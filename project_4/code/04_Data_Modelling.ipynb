{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 4 - Unveiling Chronic Disease in Singaporean Lifestyle\n",
    "\n",
    "> Authors: Chung Yau, Gilbert, Han Kiong, Zheng Gang\n",
    "---\n",
    "\n",
    "**Problem Statement:**  \n",
    "In Singapore, the increasing prevalence of chronic diseases presents a pressing public health concern, underscoring the need for proactive intervention strategies. \n",
    "\n",
    "How can we identify individuals at high risk for chronic diseases based on their behavioral habits? By doing so, we can enable early detection and provide recommendations, fostering a proactive approach to preventing various chronic diseases.\n",
    "\n",
    "  \n",
    "**Target Audience:**  \n",
    "Product team in Synapxe, in preparation for Healthier SG 2025 roadmap workshop. \n",
    "\n",
    "These are the notebooks for this project:  \n",
    " 1. `01_Data_Collection_Food.ipynb`  \n",
    " 2. `02_Data_Preprocessing.ipynb`   \n",
    " 3. `03_FeatureEngineering_and_EDA.ipynb`\n",
    " 4. `04_Data_Modelling.ipynb` \n",
    " 5. `05_Hyperparameter_Model Fitting_Evaluation.ipynb`\n",
    " 6. `05a_Model_Pickling.ipynb`\n",
    " 7. `06_Implementation_FoodRecommender.ipynb` \n",
    "\n",
    " ---\n",
    "\n",
    "# This Notebook: 04 Data Modelling\n",
    "- We will evaluate the various models in searching for the baseline model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the suitable baseline models, we first consider the interpretability and performance of the models as seen in the graph. Interpretability refers to the ease with which a model's predictions can be understood and explained while performance relates to whether the model can effectively captures patterns in the data and generalizes well to new instances.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"../assets/interpretability-vs-performance-trade-off.png\" style=\"height: 500px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below compares the pros and cons of the different classification models:\n",
    "\n",
    "| Classification Method           | Pros                                     | Cons                                                       | Usage Suggestions                                                                                                                  |\n",
    "|--------------------------------|------------------------------------------|------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Logistic Regression             | - Interpretable coefficients             | - Assumes linear relationship                             | Use for straightforward interpretation of how each feature influences the risk of chronic diseases. Suitable for cases where linear relationships between features and outcome are plausible. |\n",
    "| Decision Trees                  | - Easy to interpret and visualize       | - Prone to overfitting                                    | Use for initial exploration of feature importance and identification of relevant predictors. Prune the tree to prevent overfitting. Suitable for both numerical and categorical data. |\n",
    "| Random Forest                   | - Reduces overfitting                   | - Less interpretable than Decision Trees                  | Use for improved generalization by combining multiple decision trees. Utilize feature importance measures to understand which lifestyle factors contribute most to the risk of chronic diseases. Suitable for large datasets. |\n",
    "| Extra Trees                     | - Reduces variance further              | - Sacrifices interpretability for improved performance   | Use for faster training and potentially better performance compared to Random Forest. Particularly useful when computational resources are limited, and interpretability is not the primary concern. |\n",
    "| Support Vector Machines (SVM)   | - Effective in high-dimensional spaces | - Complexity in choosing the appropriate kernel          | Use for finding optimal hyperplanes to separate high-risk and low-risk individuals. Requires careful selection of hyperparameters and choice of kernel function. Suitable for cases with complex, non-linear relationships. |\n",
    "| k-Nearest Neighbors (k-NN)     | - Simple and intuitive                  | - Sensitive to irrelevant features                        | Use for identifying high-risk individuals based on similarity to other high-risk cases in the dataset. Normalize features and tune the number of neighbors to improve performance. Suitable for small to medium-sized datasets. |\n",
    "| Naive Bayes                     | - Computationally efficient            | - Assumes strong independence between features            | Use for quick classification of high-risk individuals based on conditional probabilities. Suitable for cases with categorical features and where independence assumptions are not severely violated. |\n",
    "| Gradient Boosting Machines (GBM)| - Combines weak learners to improve accuracy | - Can be computationally expensive and prone to overfitting | Use for building a strong predictive model by sequentially correcting errors of weak models. Regularize hyperparameters to prevent overfitting. Suitable for datasets with complex relationships and high predictive accuracy requirements. |\n",
    "| AdaBoost                        | - Sequentially combines weak learners   | - Sensitive to noisy data                                 | Use for iteratively adjusting weights to focus on previously misclassified cases. Prune weak learners to improve generalization. Suitable for ensemble learning when there's a large imbalance between high-risk and low-risk individuals. |\n",
    "| XGBoost                         | - High performance and scalability     | - Less interpretable than simpler models                  | Use for maximizing predictive accuracy and handling large datasets. Tune hyperparameters to balance bias and variance. Suitable for situations where interpretability is less critical compared to predictive power. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After considering the pros and cons in terms of interpretability and performance, we have narrowed to 5 baseline models with a good balance of interpretability and performance. \n",
    "\n",
    "| Classifier                   | Interpretability | Performance | Recommendations                                                                                                                                                                  |\n",
    "|------------------------------|------------------|-------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Logistic Regression          | High             | Moderate    | Suitable for linearly separable data, easy to interpret coefficients, works well with small to medium-sized datasets.                                                  |\n",
    "| Random Forest                | Moderate         | High        | Combines multiple decision trees to reduce overfitting, robust to noise and outliers, suitable for large datasets with high dimensionality.                            |\n",
    "| Support Vector Machines (SVM)| Low              | High        | Effective in high-dimensional spaces, versatile due to different kernel functions, can be memory intensive, suitable for small to medium-sized datasets.            |\n",
    "| Gradient Boosting Machines (GBM)| Low           | High        | Ensemble method that combines weak learners to improve accuracy, less interpretable due to complexity, suitable for various types of data.                            |\n",
    "| XGBoost                      | Low              | High        | Optimized implementation of gradient boosting, often outperforms other algorithms, less interpretable but highly accurate, suitable for large datasets.               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Obtaining cleaned dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section involves the following: \n",
    "1. importing the dataset after exploratory data analysis (EDA) is performed\n",
    "2. inspection of the dataframe, checking of null values\n",
    "3. dropping of the '_RACE' column since the dataset has been filtered to include only asian during EDA\n",
    "4. checking for the 'CD' class distribution (1: chronic and 0: not chronic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Importing the dataset after EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = '../data/03_asian_data.csv'\n",
    "\n",
    "df = pd.read_csv(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Quick view of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heart_attack</th>\n",
       "      <th>stroke</th>\n",
       "      <th>asthma</th>\n",
       "      <th>skin_cancer</th>\n",
       "      <th>other_cancer</th>\n",
       "      <th>cpd_bronchitis</th>\n",
       "      <th>depression</th>\n",
       "      <th>kidney_disease</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>sex</th>\n",
       "      <th>martial</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>blind</th>\n",
       "      <th>diff_walking</th>\n",
       "      <th>occasion_drink_30days</th>\n",
       "      <th>high_bp</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>education</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>one_alc_per_day</th>\n",
       "      <th>binge_drink</th>\n",
       "      <th>ave_drink_week</th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>exercise_cat</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>173.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.330000e+02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6804.000000</td>\n",
       "      <td>22.733803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>157.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5897.000000</td>\n",
       "      <td>23.923891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>173.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6350.000000</td>\n",
       "      <td>21.216880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.36927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8048.087779</td>\n",
       "      <td>28.055853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.170000e+02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7484.000000</td>\n",
       "      <td>23.098765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9072.000000</td>\n",
       "      <td>29.622857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5897.000000</td>\n",
       "      <td>21.660239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4536.000000</td>\n",
       "      <td>19.632964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>168.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6577.000000</td>\n",
       "      <td>23.302863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>16.326905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   heart_attack  stroke  asthma  skin_cancer  other_cancer  cpd_bronchitis  \\\n",
       "0             0       0       0            0             0               0   \n",
       "1             0       0       0            0             0               0   \n",
       "2             0       0       0            0             0               0   \n",
       "3             0       0       0            0             0               1   \n",
       "4             0       0       0            0             0               0   \n",
       "5             0       0       0            0             0               0   \n",
       "6             0       0       0            0             0               0   \n",
       "7             0       0       0            0             0               0   \n",
       "8             0       0       0            0             0               0   \n",
       "9             0       0       0            0             0               0   \n",
       "\n",
       "   depression  kidney_disease  diabetes  sex  martial  employment_status  \\\n",
       "0           0               0         0    1        1                  1   \n",
       "1           0               0         0    1        1                  1   \n",
       "2           0               0         0    1        1                  0   \n",
       "3           1               0         0    0        0                  0   \n",
       "4           0               0         0    1        1                  0   \n",
       "5           0               0         0    0        0                  1   \n",
       "6           0               0         1    1        1                  1   \n",
       "7           0               0         0    0        0                  0   \n",
       "8           0               0         0    1        0                  1   \n",
       "9           0               0         0    0        0                  1   \n",
       "\n",
       "   blind  diff_walking  occasion_drink_30days  high_bp  heart_disease  \\\n",
       "0      0             0                      5        0              0   \n",
       "1      0             0                      0        0              0   \n",
       "2      0             0                      0        1              0   \n",
       "3      0             1                      0        1              0   \n",
       "4      0             0                      5        0              0   \n",
       "5      0             0                      1        0              0   \n",
       "6      0             0                      0        0              0   \n",
       "7      0             0                      0        0              0   \n",
       "8      0             0                      0        0              0   \n",
       "9      0             0                      0        0              0   \n",
       "\n",
       "   arthritis  race   age     height  education  smoker_status  \\\n",
       "0          0     4   7.0  173.00000          2              0   \n",
       "1          0     4   3.0  157.00000          1              0   \n",
       "2          0     4  10.0  173.00000          2              0   \n",
       "3          1     4   8.0  169.36927          1              0   \n",
       "4          0     4   9.0  180.00000          2              1   \n",
       "5          0     4   1.0  175.00000          1              0   \n",
       "6          0     4   5.0  165.00000          2              1   \n",
       "7          0     4   1.0  152.00000          1              0   \n",
       "8          0     4   2.0  168.00000          2              0   \n",
       "9          0     4   1.0  165.00000          0              0   \n",
       "\n",
       "   one_alc_per_day  binge_drink  ave_drink_week  fruit  vegetable  \\\n",
       "0                1            0    2.330000e+02      0          0   \n",
       "1                0            0    5.397605e-79      0          0   \n",
       "2                0            0    5.397605e-79      0          1   \n",
       "3                0            0    5.397605e-79      0          0   \n",
       "4                1            0    1.170000e+02      1          1   \n",
       "5                1            0    4.700000e+01      1          1   \n",
       "6                0            0    5.397605e-79      0          1   \n",
       "7                0            0    5.397605e-79      0          0   \n",
       "8                0            0    5.397605e-79      0          1   \n",
       "9                0            0    5.397605e-79      1          1   \n",
       "\n",
       "   exercise_cat  high_cholesterol       weight        BMI  CD  \n",
       "0             2                 1  6804.000000  22.733803   0  \n",
       "1             0                 0  5897.000000  23.923891   0  \n",
       "2             1                 1  6350.000000  21.216880   0  \n",
       "3             1                 1  8048.087779  28.055853   1  \n",
       "4             2                 0  7484.000000  23.098765   0  \n",
       "5             1                 0  9072.000000  29.622857   0  \n",
       "6             0                 1  5897.000000  21.660239   1  \n",
       "7             1                 0  4536.000000  19.632964   0  \n",
       "8             1                 0  6577.000000  23.302863   0  \n",
       "9             2                 0  4445.000000  16.326905   0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first 10 rows of the dataframe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16104, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the rows and columns in the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['heart_attack', 'stroke', 'asthma', 'skin_cancer', 'other_cancer',\n",
       "       'cpd_bronchitis', 'depression', 'kidney_disease', 'diabetes', 'sex',\n",
       "       'martial', 'employment_status', 'blind', 'diff_walking',\n",
       "       'occasion_drink_30days', 'high_bp', 'heart_disease', 'arthritis',\n",
       "       'race', 'age', 'height', 'education', 'smoker_status',\n",
       "       'one_alc_per_day', 'binge_drink', 'ave_drink_week', 'fruit',\n",
       "       'vegetable', 'exercise_cat', 'high_cholesterol', 'weight', 'BMI', 'CD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the columns in the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "heart_attack             0\n",
       "stroke                   0\n",
       "asthma                   0\n",
       "skin_cancer              0\n",
       "other_cancer             0\n",
       "cpd_bronchitis           0\n",
       "depression               0\n",
       "kidney_disease           0\n",
       "diabetes                 0\n",
       "sex                      0\n",
       "martial                  0\n",
       "employment_status        0\n",
       "blind                    0\n",
       "diff_walking             0\n",
       "occasion_drink_30days    0\n",
       "high_bp                  0\n",
       "heart_disease            0\n",
       "arthritis                0\n",
       "race                     0\n",
       "age                      0\n",
       "height                   0\n",
       "education                0\n",
       "smoker_status            0\n",
       "one_alc_per_day          0\n",
       "binge_drink              0\n",
       "ave_drink_week           0\n",
       "fruit                    0\n",
       "vegetable                0\n",
       "exercise_cat             0\n",
       "high_cholesterol         0\n",
       "weight                   0\n",
       "BMI                      0\n",
       "CD                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null/nan values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Dropping of '_RACE' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for '_RACE'=4 (Asian)\n",
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this check, there is only 1 unique values in the '_RACE' column and confirms that the dataset has been filtered for asian during the EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop '_RACE' column\n",
    "df.drop(columns=['race'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['heart_attack', 'stroke', 'asthma', 'skin_cancer', 'other_cancer',\n",
       "       'cpd_bronchitis', 'depression', 'kidney_disease', 'diabetes', 'sex',\n",
       "       'martial', 'employment_status', 'blind', 'diff_walking',\n",
       "       'occasion_drink_30days', 'high_bp', 'heart_disease', 'arthritis', 'age',\n",
       "       'height', 'education', 'smoker_status', 'one_alc_per_day',\n",
       "       'binge_drink', 'ave_drink_week', 'fruit', 'vegetable', 'exercise_cat',\n",
       "       'high_cholesterol', 'weight', 'BMI', 'CD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns to ensure '_RACE' has been dropped\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Checking the class distribution in 'CD' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "CD\n",
      "0    10631\n",
      "1     5473\n",
      "Name: count, dtype: int64\n",
      "CD\n",
      "0    66.014655\n",
      "1    33.985345\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# finding the unique values in 'CD' column\n",
    "print(df['CD'].unique())\n",
    "\n",
    "# finding the count and percentage of 1: chronic and 0: not chronic in the 'CD' column\n",
    "print(df['CD'].value_counts())\n",
    "print(df['CD'].value_counts(normalize = True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As seen, the classes are unbalanced with 66.0% for 0 (not chronic) and 34.0% for 1 (chronic).\n",
    "- There are 2 options to balance the classes, namely undersampling or oversampling. \n",
    "- We will try both options and compare the scores for the baseline models based on undersampling and oversampling.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Transforming and Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create the models, we will be applying a few tools or techniques to do data preprocessing, feature engineering and dimensionality reduction as follows: \n",
    "\n",
    "1. Class Balancing: \n",
    "- `RandomUnderSampler` aims to balance the class distribution by randomly selecting a subset of instances from the majority class (or classes) such that the resulting dataset is more balanced. The idea is to reduce the number of instances in the majority class to match the number of instances in the minority class, thus creating a more balanced dataset for training the model.\n",
    "- `ADASYN` algorithm aims to balance the class distribution by generating synthetic samples for the minority class (class 1 in your case). However, it doesn't guarantee an exact balance between the classes after resampling. The imbalance might still exist due to the nature of the algorithm and the distribution of instances in the feature space.\n",
    "2. PolynomialFeatures: `PolynomialFeatures` is a preprocessing module that generates polynomial features from the original features useful for capturing non-linear relationships between features. For example, if you have a feature x, PolynomialFeatures can create new features like x^2, x^3, etc.\n",
    "3. StandardScaler: `StandardScaler` is a preprocessing technique used to standardize features by removing the mean and scaling to unit variance. We apply to numerical features to ensure that they have a mean of 0 and a standard deviation of 1. This is important for many machine learning algorithms that assume data is centered and has a consistent scale.\n",
    "4. Principal Component Analysis: `PCA` is a dimensionality reduction technique used to reduce the number of features in a dataset while preserving most of the information. It does this by transforming the original features into a new set of orthogonal (uncorrelated) features called principal components. These principal components are ordered by the amount of variance they explain in the data, allowing you to select a subset of components to represent the data more efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Determine the n_component for PCA\n",
    "\n",
    "As we will be generating polynomial features from the original features, we are interested in reducing the dimensions as a result of these additional polynomial features. \n",
    "\n",
    "In order to determine the n_component for PCA, we will perform the following steps:\n",
    "1. Balance our data by undersampling (with RandomUnderSampler) or oversampling (with ADASYN) (undersamping is chosen eventually)\n",
    "2. Polynomial feature the numeric continous columns \n",
    "2. Standardscale our data before applying PCA (to prevent features with high scale from dominating the calculation)\n",
    "2. Instantiate, fit and transform PCA on the scaled training data\n",
    "3. Transform PCA on the test data\n",
    "4. Pull the explained variance attribute (to explain the amount of variance by each of the newly created principal components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into training and testing sets.\n",
    "# set a custom test size of 20% for model evaluation.\n",
    "columns_to_check = [\n",
    "    'cpd_bronchitis',  \n",
    "    'depression',    \n",
    "    'arthritis',      \n",
    "    'heart_attack',   \n",
    "    'stroke',        \n",
    "    'asthma',       \n",
    "    'diabetes',      \n",
    "    'kidney_disease', \n",
    "    'heart_disease',  \n",
    "    'CD',        \n",
    "    'height',        \n",
    "    'weight'        \n",
    "]\n",
    "\n",
    "X_pca = df.drop(columns=['CD'])\n",
    "y_pca = df['CD']\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y_pca, test_size=0.2, random_state=42, stratify=y_pca)\n",
    "\n",
    "# Apply ADASYN to balance the classes\n",
    "rus = RandomUnderSampler(random_state = 42)\n",
    "X_train_resampled_p, y_train_resampled_p = rus.fit_resample(X_train_pca, y_train_pca)\n",
    "\n",
    "# Define columns you want to apply polynomial features to\n",
    "poly_cols = [\n",
    "    'occasion_drink_30days', \n",
    "    'BMI',                \n",
    "    'education',          \n",
    "    'smoker_status',       \n",
    "    'exercise_cat',    \n",
    "    'ave_drink_week',     \n",
    "    'age'              \n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply PolynomialFeatures to selected columns\n",
    "poly_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), poly_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through columns not specified for polynomial features\n",
    ")\n",
    "\n",
    "# Fit and transform the resampled data with polynomial features\n",
    "X_train_poly_resampled = poly_transformer.fit_transform(X_train_resampled_p)\n",
    "X_test_poly = poly_transformer.transform(X_test_pca)\n",
    "\n",
    "# Standard scale the resampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_sc_resampled = scaler.fit_transform(X_train_poly_resampled)\n",
    "X_test_sc = scaler.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.601840</td>\n",
       "      <td>-0.640847</td>\n",
       "      <td>-0.983666</td>\n",
       "      <td>0.026669</td>\n",
       "      <td>0.774594</td>\n",
       "      <td>-1.874834</td>\n",
       "      <td>-0.378492</td>\n",
       "      <td>-1.894257</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>0.283224</td>\n",
       "      <td>-0.151174</td>\n",
       "      <td>-0.254283</td>\n",
       "      <td>-0.106419</td>\n",
       "      <td>0.355358</td>\n",
       "      <td>0.673602</td>\n",
       "      <td>0.830963</td>\n",
       "      <td>0.193680</td>\n",
       "      <td>0.222186</td>\n",
       "      <td>0.116804</td>\n",
       "      <td>0.435427</td>\n",
       "      <td>-0.433507</td>\n",
       "      <td>-0.407057</td>\n",
       "      <td>0.124259</td>\n",
       "      <td>-0.023591</td>\n",
       "      <td>0.390032</td>\n",
       "      <td>-1.717121</td>\n",
       "      <td>0.243338</td>\n",
       "      <td>-0.168488</td>\n",
       "      <td>0.186589</td>\n",
       "      <td>-0.289199</td>\n",
       "      <td>0.368435</td>\n",
       "      <td>0.165026</td>\n",
       "      <td>-0.238586</td>\n",
       "      <td>-0.063236</td>\n",
       "      <td>0.012520</td>\n",
       "      <td>0.319738</td>\n",
       "      <td>-0.073011</td>\n",
       "      <td>0.093482</td>\n",
       "      <td>-0.054032</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.232622</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.030311</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>-0.028131</td>\n",
       "      <td>0.259480</td>\n",
       "      <td>-0.143949</td>\n",
       "      <td>-0.002596</td>\n",
       "      <td>-0.038614</td>\n",
       "      <td>-0.004471</td>\n",
       "      <td>0.054296</td>\n",
       "      <td>-0.025513</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>-0.012486</td>\n",
       "      <td>-0.076529</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>0.051977</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>2.088207e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.231852</td>\n",
       "      <td>-2.346142</td>\n",
       "      <td>-0.996811</td>\n",
       "      <td>2.698839</td>\n",
       "      <td>0.405108</td>\n",
       "      <td>0.323427</td>\n",
       "      <td>-0.908849</td>\n",
       "      <td>-0.785838</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>0.428181</td>\n",
       "      <td>-0.021008</td>\n",
       "      <td>0.215787</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.287076</td>\n",
       "      <td>-0.056573</td>\n",
       "      <td>0.590981</td>\n",
       "      <td>-0.452951</td>\n",
       "      <td>0.372590</td>\n",
       "      <td>-0.148825</td>\n",
       "      <td>0.257114</td>\n",
       "      <td>-0.093216</td>\n",
       "      <td>0.448759</td>\n",
       "      <td>-0.358268</td>\n",
       "      <td>-0.198548</td>\n",
       "      <td>0.505185</td>\n",
       "      <td>1.422810</td>\n",
       "      <td>-0.149852</td>\n",
       "      <td>-0.427276</td>\n",
       "      <td>-0.339285</td>\n",
       "      <td>-0.067443</td>\n",
       "      <td>0.426936</td>\n",
       "      <td>-0.231448</td>\n",
       "      <td>0.080221</td>\n",
       "      <td>0.037616</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>-0.187752</td>\n",
       "      <td>-0.173375</td>\n",
       "      <td>0.163607</td>\n",
       "      <td>-0.409616</td>\n",
       "      <td>-0.020111</td>\n",
       "      <td>-0.192068</td>\n",
       "      <td>0.094978</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.040471</td>\n",
       "      <td>0.083877</td>\n",
       "      <td>-0.090021</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>-0.050653</td>\n",
       "      <td>-0.054207</td>\n",
       "      <td>-0.066739</td>\n",
       "      <td>-0.015158</td>\n",
       "      <td>0.040304</td>\n",
       "      <td>-0.050093</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>-0.008864</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>6.152584e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.377791</td>\n",
       "      <td>-1.174135</td>\n",
       "      <td>-1.960025</td>\n",
       "      <td>1.842926</td>\n",
       "      <td>-0.784641</td>\n",
       "      <td>-0.450303</td>\n",
       "      <td>0.531102</td>\n",
       "      <td>0.602361</td>\n",
       "      <td>0.563252</td>\n",
       "      <td>0.194218</td>\n",
       "      <td>-1.127771</td>\n",
       "      <td>-0.283244</td>\n",
       "      <td>0.525885</td>\n",
       "      <td>0.398710</td>\n",
       "      <td>0.196922</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>0.220244</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>0.072242</td>\n",
       "      <td>0.231779</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.461692</td>\n",
       "      <td>0.245807</td>\n",
       "      <td>1.072430</td>\n",
       "      <td>0.621528</td>\n",
       "      <td>-1.267783</td>\n",
       "      <td>0.807717</td>\n",
       "      <td>0.357322</td>\n",
       "      <td>0.353899</td>\n",
       "      <td>-0.155698</td>\n",
       "      <td>-0.270258</td>\n",
       "      <td>0.071122</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.122814</td>\n",
       "      <td>0.102884</td>\n",
       "      <td>-0.045922</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>-0.107396</td>\n",
       "      <td>0.074456</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.138601</td>\n",
       "      <td>-0.048610</td>\n",
       "      <td>-0.071922</td>\n",
       "      <td>-0.141192</td>\n",
       "      <td>-0.021444</td>\n",
       "      <td>0.175808</td>\n",
       "      <td>0.035646</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.043521</td>\n",
       "      <td>-0.003171</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>-0.088369</td>\n",
       "      <td>0.023391</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>4.694717e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.123105</td>\n",
       "      <td>2.529432</td>\n",
       "      <td>1.755920</td>\n",
       "      <td>-2.939549</td>\n",
       "      <td>0.265498</td>\n",
       "      <td>-0.689957</td>\n",
       "      <td>0.907990</td>\n",
       "      <td>0.016157</td>\n",
       "      <td>-0.330340</td>\n",
       "      <td>-0.812595</td>\n",
       "      <td>1.154606</td>\n",
       "      <td>0.170770</td>\n",
       "      <td>-0.747311</td>\n",
       "      <td>0.497810</td>\n",
       "      <td>-0.695236</td>\n",
       "      <td>-0.373344</td>\n",
       "      <td>0.062177</td>\n",
       "      <td>0.456499</td>\n",
       "      <td>-0.597408</td>\n",
       "      <td>-0.295702</td>\n",
       "      <td>0.331352</td>\n",
       "      <td>1.085464</td>\n",
       "      <td>-0.158075</td>\n",
       "      <td>0.048308</td>\n",
       "      <td>-1.235012</td>\n",
       "      <td>-0.384014</td>\n",
       "      <td>-2.001023</td>\n",
       "      <td>-1.953641</td>\n",
       "      <td>-0.978375</td>\n",
       "      <td>-0.285097</td>\n",
       "      <td>-0.171234</td>\n",
       "      <td>-0.596076</td>\n",
       "      <td>0.469973</td>\n",
       "      <td>-0.023008</td>\n",
       "      <td>0.404738</td>\n",
       "      <td>-0.600903</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0.130373</td>\n",
       "      <td>-0.214514</td>\n",
       "      <td>0.107131</td>\n",
       "      <td>0.154791</td>\n",
       "      <td>0.225228</td>\n",
       "      <td>-0.193171</td>\n",
       "      <td>0.108287</td>\n",
       "      <td>-0.257320</td>\n",
       "      <td>-0.192196</td>\n",
       "      <td>0.128299</td>\n",
       "      <td>-0.086849</td>\n",
       "      <td>0.101524</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>-0.020154</td>\n",
       "      <td>0.017666</td>\n",
       "      <td>0.056740</td>\n",
       "      <td>0.095671</td>\n",
       "      <td>0.066224</td>\n",
       "      <td>-0.012885</td>\n",
       "      <td>0.069428</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>-0.011683</td>\n",
       "      <td>1.105160e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.761358</td>\n",
       "      <td>-2.251735</td>\n",
       "      <td>0.878684</td>\n",
       "      <td>1.131911</td>\n",
       "      <td>-2.250111</td>\n",
       "      <td>1.961381</td>\n",
       "      <td>0.142625</td>\n",
       "      <td>0.443099</td>\n",
       "      <td>0.465713</td>\n",
       "      <td>0.240151</td>\n",
       "      <td>-0.402122</td>\n",
       "      <td>-0.209633</td>\n",
       "      <td>0.672818</td>\n",
       "      <td>0.616404</td>\n",
       "      <td>-0.213678</td>\n",
       "      <td>-0.430959</td>\n",
       "      <td>0.423286</td>\n",
       "      <td>-0.131839</td>\n",
       "      <td>-0.260334</td>\n",
       "      <td>-0.466644</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>0.309171</td>\n",
       "      <td>0.174355</td>\n",
       "      <td>-0.347072</td>\n",
       "      <td>-0.475326</td>\n",
       "      <td>1.145155</td>\n",
       "      <td>-0.563235</td>\n",
       "      <td>0.403334</td>\n",
       "      <td>0.039631</td>\n",
       "      <td>0.509803</td>\n",
       "      <td>-0.554643</td>\n",
       "      <td>-0.384968</td>\n",
       "      <td>0.314884</td>\n",
       "      <td>0.091894</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>-0.265742</td>\n",
       "      <td>0.254026</td>\n",
       "      <td>0.063820</td>\n",
       "      <td>-0.384125</td>\n",
       "      <td>0.219231</td>\n",
       "      <td>0.227178</td>\n",
       "      <td>-0.354058</td>\n",
       "      <td>0.326576</td>\n",
       "      <td>0.013438</td>\n",
       "      <td>-0.028200</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>0.031667</td>\n",
       "      <td>-0.133025</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>-0.064845</td>\n",
       "      <td>-0.020966</td>\n",
       "      <td>0.021561</td>\n",
       "      <td>0.014850</td>\n",
       "      <td>-0.040136</td>\n",
       "      <td>-0.075612</td>\n",
       "      <td>0.052611</td>\n",
       "      <td>-0.032804</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>-0.001397</td>\n",
       "      <td>1.733881e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.601840 -0.640847 -0.983666  0.026669  0.774594 -1.874834 -0.378492   \n",
       "1  1.231852 -2.346142 -0.996811  2.698839  0.405108  0.323427 -0.908849   \n",
       "2 -1.377791 -1.174135 -1.960025  1.842926 -0.784641 -0.450303  0.531102   \n",
       "3 -2.123105  2.529432  1.755920 -2.939549  0.265498 -0.689957  0.907990   \n",
       "4 -1.761358 -2.251735  0.878684  1.131911 -2.250111  1.961381  0.142625   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -1.894257  0.019284  0.283224 -0.151174 -0.254283 -0.106419  0.355358   \n",
       "1 -0.785838  0.014770  0.428181 -0.021008  0.215787 -0.019156 -0.287076   \n",
       "2  0.602361  0.563252  0.194218 -1.127771 -0.283244  0.525885  0.398710   \n",
       "3  0.016157 -0.330340 -0.812595  1.154606  0.170770 -0.747311  0.497810   \n",
       "4  0.443099  0.465713  0.240151 -0.402122 -0.209633  0.672818  0.616404   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0  0.673602  0.830963  0.193680  0.222186  0.116804  0.435427 -0.433507   \n",
       "1 -0.056573  0.590981 -0.452951  0.372590 -0.148825  0.257114 -0.093216   \n",
       "2  0.196922  0.041428  0.220244  0.014736 -0.015110  0.072242  0.231779   \n",
       "3 -0.695236 -0.373344  0.062177  0.456499 -0.597408 -0.295702  0.331352   \n",
       "4 -0.213678 -0.430959  0.423286 -0.131839 -0.260334 -0.466644 -0.002420   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0 -0.407057  0.124259 -0.023591  0.390032 -1.717121  0.243338 -0.168488   \n",
       "1  0.448759 -0.358268 -0.198548  0.505185  1.422810 -0.149852 -0.427276   \n",
       "2 -0.004365  0.461692  0.245807  1.072430  0.621528 -1.267783  0.807717   \n",
       "3  1.085464 -0.158075  0.048308 -1.235012 -0.384014 -2.001023 -1.953641   \n",
       "4  0.309171  0.174355 -0.347072 -0.475326  1.145155 -0.563235  0.403334   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0  0.186589 -0.289199  0.368435  0.165026 -0.238586 -0.063236  0.012520   \n",
       "1 -0.339285 -0.067443  0.426936 -0.231448  0.080221  0.037616  0.067108   \n",
       "2  0.357322  0.353899 -0.155698 -0.270258  0.071122  0.002615  0.122814   \n",
       "3 -0.978375 -0.285097 -0.171234 -0.596076  0.469973 -0.023008  0.404738   \n",
       "4  0.039631  0.509803 -0.554643 -0.384968  0.314884  0.091894  0.058430   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0  0.319738 -0.073011  0.093482 -0.054032  0.020647  0.232622  0.004366   \n",
       "1 -0.187752 -0.173375  0.163607 -0.409616 -0.020111 -0.192068  0.094978   \n",
       "2  0.102884 -0.045922  0.075392 -0.107396  0.074456 -0.009381  0.000629   \n",
       "3 -0.600903  0.115645  0.130373 -0.214514  0.107131  0.154791  0.225228   \n",
       "4 -0.265742  0.254026  0.063820 -0.384125  0.219231  0.227178 -0.354058   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0 -0.030311  0.005392 -0.028131  0.259480 -0.143949 -0.002596 -0.038614   \n",
       "1  0.006406  0.040471  0.083877 -0.090021  0.014841 -0.050653 -0.054207   \n",
       "2 -0.138601 -0.048610 -0.071922 -0.141192 -0.021444  0.175808  0.035646   \n",
       "3 -0.193171  0.108287 -0.257320 -0.192196  0.128299 -0.086849  0.101524   \n",
       "4  0.326576  0.013438 -0.028200 -0.036865  0.031667 -0.133025 -0.005694   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0 -0.004471  0.054296 -0.025513  0.008078 -0.012486 -0.076529  0.003102   \n",
       "1 -0.066739 -0.015158  0.040304 -0.050093  0.007385  0.003378  0.008272   \n",
       "2  0.001228  0.043521 -0.003171  0.001530  0.027751  0.024552 -0.088369   \n",
       "3 -0.009368 -0.020154  0.017666  0.056740  0.095671  0.066224 -0.012885   \n",
       "4 -0.064845 -0.020966  0.021561  0.014850 -0.040136 -0.075612  0.052611   \n",
       "\n",
       "         56        57        58            59  \n",
       "0  0.025376  0.051977  0.003774  2.088207e-14  \n",
       "1 -0.008864  0.015461 -0.006014  6.152584e-18  \n",
       "2  0.023391  0.009392  0.010279  4.694717e-18  \n",
       "3  0.069428  0.017746 -0.011683  1.105160e-17  \n",
       "4 -0.032804  0.013523 -0.001397  1.733881e-17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate PCA.\n",
    "pca = PCA(random_state = 42)\n",
    "\n",
    "# Fit and Transform PCA on the scaled training data from X_train_sc to Z_train (PC) features.\n",
    "Z_train = pca.fit_transform(X_train_sc_resampled)\n",
    "\n",
    "# Check out the results in a dataframe.\n",
    "pd.DataFrame(Z_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.828254</td>\n",
       "      <td>0.119166</td>\n",
       "      <td>0.135020</td>\n",
       "      <td>3.671401</td>\n",
       "      <td>-1.020140</td>\n",
       "      <td>-1.229569</td>\n",
       "      <td>-0.465638</td>\n",
       "      <td>-0.521695</td>\n",
       "      <td>0.601154</td>\n",
       "      <td>0.176956</td>\n",
       "      <td>-0.309730</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>-0.433906</td>\n",
       "      <td>-0.122126</td>\n",
       "      <td>0.656998</td>\n",
       "      <td>-0.132899</td>\n",
       "      <td>0.510841</td>\n",
       "      <td>-0.082842</td>\n",
       "      <td>0.324439</td>\n",
       "      <td>-0.086460</td>\n",
       "      <td>0.445156</td>\n",
       "      <td>-0.453181</td>\n",
       "      <td>0.070990</td>\n",
       "      <td>-0.148505</td>\n",
       "      <td>0.626066</td>\n",
       "      <td>-0.982034</td>\n",
       "      <td>0.712641</td>\n",
       "      <td>-0.010345</td>\n",
       "      <td>0.154753</td>\n",
       "      <td>0.032808</td>\n",
       "      <td>0.807478</td>\n",
       "      <td>-0.971187</td>\n",
       "      <td>-0.011545</td>\n",
       "      <td>-0.131402</td>\n",
       "      <td>-0.198993</td>\n",
       "      <td>0.612741</td>\n",
       "      <td>0.061333</td>\n",
       "      <td>-0.333821</td>\n",
       "      <td>0.169366</td>\n",
       "      <td>-0.082504</td>\n",
       "      <td>0.343993</td>\n",
       "      <td>-0.236122</td>\n",
       "      <td>0.226492</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>-0.212631</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.134088</td>\n",
       "      <td>-0.031998</td>\n",
       "      <td>-0.017881</td>\n",
       "      <td>-0.013068</td>\n",
       "      <td>-0.059459</td>\n",
       "      <td>0.073184</td>\n",
       "      <td>0.124520</td>\n",
       "      <td>-0.019338</td>\n",
       "      <td>0.044046</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>-0.029107</td>\n",
       "      <td>-0.008535</td>\n",
       "      <td>2.593443e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.848268</td>\n",
       "      <td>2.326184</td>\n",
       "      <td>5.530766</td>\n",
       "      <td>2.633174</td>\n",
       "      <td>-0.285820</td>\n",
       "      <td>-4.469285</td>\n",
       "      <td>0.478753</td>\n",
       "      <td>0.695374</td>\n",
       "      <td>0.631102</td>\n",
       "      <td>-1.128967</td>\n",
       "      <td>0.924448</td>\n",
       "      <td>-0.418833</td>\n",
       "      <td>-0.186514</td>\n",
       "      <td>-0.751774</td>\n",
       "      <td>-1.689482</td>\n",
       "      <td>0.311650</td>\n",
       "      <td>0.528028</td>\n",
       "      <td>0.534501</td>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.418879</td>\n",
       "      <td>0.240262</td>\n",
       "      <td>0.273396</td>\n",
       "      <td>-0.261327</td>\n",
       "      <td>0.802925</td>\n",
       "      <td>-0.488801</td>\n",
       "      <td>-0.459396</td>\n",
       "      <td>-0.056920</td>\n",
       "      <td>0.314993</td>\n",
       "      <td>-0.254198</td>\n",
       "      <td>0.637259</td>\n",
       "      <td>0.605876</td>\n",
       "      <td>-2.075718</td>\n",
       "      <td>0.640686</td>\n",
       "      <td>-0.019890</td>\n",
       "      <td>-1.701113</td>\n",
       "      <td>0.871178</td>\n",
       "      <td>1.704187</td>\n",
       "      <td>-0.715255</td>\n",
       "      <td>0.433265</td>\n",
       "      <td>-0.275521</td>\n",
       "      <td>-0.920652</td>\n",
       "      <td>-0.404637</td>\n",
       "      <td>0.234945</td>\n",
       "      <td>0.184116</td>\n",
       "      <td>0.497862</td>\n",
       "      <td>0.269911</td>\n",
       "      <td>-0.118069</td>\n",
       "      <td>0.201996</td>\n",
       "      <td>-0.014644</td>\n",
       "      <td>0.045696</td>\n",
       "      <td>-0.034928</td>\n",
       "      <td>-0.085613</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.172408</td>\n",
       "      <td>0.170384</td>\n",
       "      <td>0.277750</td>\n",
       "      <td>0.151340</td>\n",
       "      <td>-0.058419</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>8.375107e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.960326</td>\n",
       "      <td>1.272612</td>\n",
       "      <td>-2.402175</td>\n",
       "      <td>-1.403092</td>\n",
       "      <td>-3.448164</td>\n",
       "      <td>0.468886</td>\n",
       "      <td>0.814892</td>\n",
       "      <td>0.393272</td>\n",
       "      <td>-0.035223</td>\n",
       "      <td>0.209374</td>\n",
       "      <td>0.125957</td>\n",
       "      <td>0.373020</td>\n",
       "      <td>-0.421528</td>\n",
       "      <td>1.134400</td>\n",
       "      <td>-0.362347</td>\n",
       "      <td>-0.642886</td>\n",
       "      <td>-1.713634</td>\n",
       "      <td>-0.301525</td>\n",
       "      <td>-0.650167</td>\n",
       "      <td>-0.186636</td>\n",
       "      <td>-0.425797</td>\n",
       "      <td>-2.587938</td>\n",
       "      <td>1.291566</td>\n",
       "      <td>0.051774</td>\n",
       "      <td>-0.138538</td>\n",
       "      <td>-0.400764</td>\n",
       "      <td>-0.709612</td>\n",
       "      <td>-0.477415</td>\n",
       "      <td>1.282393</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>0.518860</td>\n",
       "      <td>0.135723</td>\n",
       "      <td>0.204726</td>\n",
       "      <td>-0.114863</td>\n",
       "      <td>-0.314939</td>\n",
       "      <td>0.067155</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>-0.337146</td>\n",
       "      <td>0.429561</td>\n",
       "      <td>-0.161309</td>\n",
       "      <td>-0.313517</td>\n",
       "      <td>0.033219</td>\n",
       "      <td>0.188475</td>\n",
       "      <td>0.191447</td>\n",
       "      <td>0.134293</td>\n",
       "      <td>-0.134077</td>\n",
       "      <td>0.112312</td>\n",
       "      <td>-0.299560</td>\n",
       "      <td>0.081411</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>-0.060027</td>\n",
       "      <td>-0.025852</td>\n",
       "      <td>-0.104491</td>\n",
       "      <td>-0.097263</td>\n",
       "      <td>0.042904</td>\n",
       "      <td>-0.033106</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>2.225037e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.721622</td>\n",
       "      <td>-1.771054</td>\n",
       "      <td>0.601862</td>\n",
       "      <td>1.024124</td>\n",
       "      <td>-2.045282</td>\n",
       "      <td>2.014134</td>\n",
       "      <td>-0.571373</td>\n",
       "      <td>-0.254063</td>\n",
       "      <td>-0.137017</td>\n",
       "      <td>-0.139633</td>\n",
       "      <td>0.884626</td>\n",
       "      <td>0.331600</td>\n",
       "      <td>0.295163</td>\n",
       "      <td>0.791238</td>\n",
       "      <td>-0.141246</td>\n",
       "      <td>-1.322553</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>-0.378826</td>\n",
       "      <td>-0.236459</td>\n",
       "      <td>-0.646737</td>\n",
       "      <td>0.309525</td>\n",
       "      <td>0.322643</td>\n",
       "      <td>0.402555</td>\n",
       "      <td>0.052024</td>\n",
       "      <td>-0.588946</td>\n",
       "      <td>-0.017743</td>\n",
       "      <td>0.065785</td>\n",
       "      <td>0.390461</td>\n",
       "      <td>-1.852833</td>\n",
       "      <td>0.598112</td>\n",
       "      <td>0.192919</td>\n",
       "      <td>-0.098404</td>\n",
       "      <td>-1.012435</td>\n",
       "      <td>-0.044070</td>\n",
       "      <td>-0.068865</td>\n",
       "      <td>-0.347044</td>\n",
       "      <td>0.110554</td>\n",
       "      <td>0.105284</td>\n",
       "      <td>-0.312198</td>\n",
       "      <td>0.256797</td>\n",
       "      <td>0.268424</td>\n",
       "      <td>-0.297244</td>\n",
       "      <td>0.332091</td>\n",
       "      <td>-0.006504</td>\n",
       "      <td>0.030045</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.063937</td>\n",
       "      <td>0.038348</td>\n",
       "      <td>-0.062740</td>\n",
       "      <td>-0.016695</td>\n",
       "      <td>0.044203</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>-0.042630</td>\n",
       "      <td>-0.096724</td>\n",
       "      <td>0.037589</td>\n",
       "      <td>-0.034523</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>-0.007255</td>\n",
       "      <td>7.004372e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.863347</td>\n",
       "      <td>3.744723</td>\n",
       "      <td>5.950885</td>\n",
       "      <td>4.325532</td>\n",
       "      <td>-4.330916</td>\n",
       "      <td>-0.298262</td>\n",
       "      <td>0.723980</td>\n",
       "      <td>0.814940</td>\n",
       "      <td>0.459177</td>\n",
       "      <td>-0.638528</td>\n",
       "      <td>-2.451201</td>\n",
       "      <td>0.498072</td>\n",
       "      <td>0.891528</td>\n",
       "      <td>-0.095250</td>\n",
       "      <td>1.195335</td>\n",
       "      <td>0.106233</td>\n",
       "      <td>-0.290831</td>\n",
       "      <td>-0.279587</td>\n",
       "      <td>-0.154653</td>\n",
       "      <td>-0.226517</td>\n",
       "      <td>0.342977</td>\n",
       "      <td>1.229269</td>\n",
       "      <td>0.656798</td>\n",
       "      <td>-1.831250</td>\n",
       "      <td>1.477580</td>\n",
       "      <td>-0.585054</td>\n",
       "      <td>0.312511</td>\n",
       "      <td>-0.201685</td>\n",
       "      <td>-0.220040</td>\n",
       "      <td>-2.000678</td>\n",
       "      <td>-0.629451</td>\n",
       "      <td>1.602714</td>\n",
       "      <td>0.490555</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>-0.999357</td>\n",
       "      <td>1.538656</td>\n",
       "      <td>-0.965553</td>\n",
       "      <td>0.593470</td>\n",
       "      <td>-0.775236</td>\n",
       "      <td>0.393924</td>\n",
       "      <td>-0.050962</td>\n",
       "      <td>-0.469339</td>\n",
       "      <td>0.413895</td>\n",
       "      <td>-0.151793</td>\n",
       "      <td>0.242871</td>\n",
       "      <td>-0.192525</td>\n",
       "      <td>0.142467</td>\n",
       "      <td>-0.097485</td>\n",
       "      <td>0.212941</td>\n",
       "      <td>0.220781</td>\n",
       "      <td>-0.029249</td>\n",
       "      <td>-0.378663</td>\n",
       "      <td>0.225277</td>\n",
       "      <td>0.074959</td>\n",
       "      <td>-0.018888</td>\n",
       "      <td>0.186607</td>\n",
       "      <td>0.084210</td>\n",
       "      <td>-0.090319</td>\n",
       "      <td>0.066228</td>\n",
       "      <td>-3.556460e-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.828254  0.119166  0.135020  3.671401 -1.020140 -1.229569 -0.465638   \n",
       "1 -0.848268  2.326184  5.530766  2.633174 -0.285820 -4.469285  0.478753   \n",
       "2 -1.960326  1.272612 -2.402175 -1.403092 -3.448164  0.468886  0.814892   \n",
       "3 -1.721622 -1.771054  0.601862  1.024124 -2.045282  2.014134 -0.571373   \n",
       "4  4.863347  3.744723  5.950885  4.325532 -4.330916 -0.298262  0.723980   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.521695  0.601154  0.176956 -0.309730  0.167770  0.033939 -0.433906   \n",
       "1  0.695374  0.631102 -1.128967  0.924448 -0.418833 -0.186514 -0.751774   \n",
       "2  0.393272 -0.035223  0.209374  0.125957  0.373020 -0.421528  1.134400   \n",
       "3 -0.254063 -0.137017 -0.139633  0.884626  0.331600  0.295163  0.791238   \n",
       "4  0.814940  0.459177 -0.638528 -2.451201  0.498072  0.891528 -0.095250   \n",
       "\n",
       "         14        15        16        17        18        19        20  \\\n",
       "0 -0.122126  0.656998 -0.132899  0.510841 -0.082842  0.324439 -0.086460   \n",
       "1 -1.689482  0.311650  0.528028  0.534501 -0.031267  0.418879  0.240262   \n",
       "2 -0.362347 -0.642886 -1.713634 -0.301525 -0.650167 -0.186636 -0.425797   \n",
       "3 -0.141246 -1.322553  0.544381 -0.378826 -0.236459 -0.646737  0.309525   \n",
       "4  1.195335  0.106233 -0.290831 -0.279587 -0.154653 -0.226517  0.342977   \n",
       "\n",
       "         21        22        23        24        25        26        27  \\\n",
       "0  0.445156 -0.453181  0.070990 -0.148505  0.626066 -0.982034  0.712641   \n",
       "1  0.273396 -0.261327  0.802925 -0.488801 -0.459396 -0.056920  0.314993   \n",
       "2 -2.587938  1.291566  0.051774 -0.138538 -0.400764 -0.709612 -0.477415   \n",
       "3  0.322643  0.402555  0.052024 -0.588946 -0.017743  0.065785  0.390461   \n",
       "4  1.229269  0.656798 -1.831250  1.477580 -0.585054  0.312511 -0.201685   \n",
       "\n",
       "         28        29        30        31        32        33        34  \\\n",
       "0 -0.010345  0.154753  0.032808  0.807478 -0.971187 -0.011545 -0.131402   \n",
       "1 -0.254198  0.637259  0.605876 -2.075718  0.640686 -0.019890 -1.701113   \n",
       "2  1.282393  0.022755  0.518860  0.135723  0.204726 -0.114863 -0.314939   \n",
       "3 -1.852833  0.598112  0.192919 -0.098404 -1.012435 -0.044070 -0.068865   \n",
       "4 -0.220040 -2.000678 -0.629451  1.602714  0.490555  0.013600 -0.999357   \n",
       "\n",
       "         35        36        37        38        39        40        41  \\\n",
       "0 -0.198993  0.612741  0.061333 -0.333821  0.169366 -0.082504  0.343993   \n",
       "1  0.871178  1.704187 -0.715255  0.433265 -0.275521 -0.920652 -0.404637   \n",
       "2  0.067155  0.014881 -0.337146  0.429561 -0.161309 -0.313517  0.033219   \n",
       "3 -0.347044  0.110554  0.105284 -0.312198  0.256797  0.268424 -0.297244   \n",
       "4  1.538656 -0.965553  0.593470 -0.775236  0.393924 -0.050962 -0.469339   \n",
       "\n",
       "         42        43        44        45        46        47        48  \\\n",
       "0 -0.236122  0.226492  0.022399 -0.212631  0.011712  0.134088 -0.031998   \n",
       "1  0.234945  0.184116  0.497862  0.269911 -0.118069  0.201996 -0.014644   \n",
       "2  0.188475  0.191447  0.134293 -0.134077  0.112312 -0.299560  0.081411   \n",
       "3  0.332091 -0.006504  0.030045 -0.003095  0.000611 -0.063937  0.038348   \n",
       "4  0.413895 -0.151793  0.242871 -0.192525  0.142467 -0.097485  0.212941   \n",
       "\n",
       "         49        50        51        52        53        54        55  \\\n",
       "0 -0.017881 -0.013068 -0.059459  0.073184  0.124520 -0.019338  0.044046   \n",
       "1  0.045696 -0.034928 -0.085613  0.048076  0.172408  0.170384  0.277750   \n",
       "2  0.012269  0.004247  0.049621 -0.060027 -0.025852 -0.104491 -0.097263   \n",
       "3 -0.062740 -0.016695  0.044203  0.013206 -0.042630 -0.096724  0.037589   \n",
       "4  0.220781 -0.029249 -0.378663  0.225277  0.074959 -0.018888  0.186607   \n",
       "\n",
       "         56        57        58            59  \n",
       "0  0.082331 -0.029107 -0.008535  2.593443e-18  \n",
       "1  0.151340 -0.058419 -0.021100  8.375107e-18  \n",
       "2  0.042904 -0.033106  0.003704  2.225037e-18  \n",
       "3 -0.034523 -0.007910 -0.007255  7.004372e-18  \n",
       "4  0.084210 -0.090319  0.066228 -3.556460e-18  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "Z_test = pca.transform(X_test_sc)\n",
    "\n",
    "# Check out the results in a dataframe.\n",
    "pd.DataFrame(Z_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance (first 40 components): [0.197 0.104 0.091 0.071 0.058 0.048 0.032 0.027 0.023 0.022 0.02  0.018\n",
      " 0.018 0.018 0.017 0.016 0.015 0.015 0.015 0.014 0.014 0.014 0.013 0.012\n",
      " 0.012 0.011 0.011 0.01  0.01  0.007 0.006 0.005 0.005 0.004 0.004 0.003\n",
      " 0.003 0.002 0.002 0.002]\n"
     ]
    }
   ],
   "source": [
    "# Pull the explained variance attribute using ready-to-use method from sklearn's PCA.\n",
    "# We can directly use this to explain the amount of variance explained by each of our newly created principal components\n",
    "var_exp = pca.explained_variance_ratio_\n",
    "print(f'Explained variance (first 40 components): {np.round(var_exp[:40],3)}') # examine only 1st 40 variances, rounded to 3 decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "- The 1st principal component alone, can explain 19.% of the entire variation in the data\n",
    "- The 2nd principal component alone, can explain 10.% of the entire variation in the data\n",
    "- The 3rd principal component alone, can explain 9.1% of the entire variation in the data\n",
    "and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative explained variance (first 40 components): [0.197 0.301 0.393 0.463 0.521 0.569 0.601 0.628 0.651 0.673 0.693 0.712\n",
      " 0.73  0.747 0.764 0.78  0.795 0.81  0.825 0.839 0.853 0.867 0.88  0.892\n",
      " 0.904 0.915 0.926 0.936 0.946 0.953 0.958 0.964 0.969 0.973 0.977 0.98\n",
      " 0.982 0.985 0.987 0.989]\n"
     ]
    }
   ],
   "source": [
    "# Generate the cumulative explained variance.\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Cumulative explained variance (first 40 components): {np.round(cum_var_exp[:40],3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "- 1st 3 principal components can explain 39.3% of the variation in the data\n",
    "- 1st 18 principal components can explain 81% of the variation in the data\n",
    "- 1st 30 principal components can explain 95.3% of the variation in the data\n",
    "\n",
    "Given that we want to explain at least 95% of the variability in my data with principal components, the smallest number of principal components that we would need to keep is 30. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the classification models, we will do the following:\n",
    "1. Define X and y\n",
    "2. Create a train-test split of X and y\n",
    "3. Create a pipeline for the RandomUnderSampler/ ADASYN, PolynomialFeatures, StandardScaler, PCA (with identified n_components) and the classifiers<br>\n",
    "4. Call and fit the respective classification models\n",
    "5. Generate scoring metrics (accuracy, precision, recall, F1 score) to see how well the baseline model is performing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Transforming and Modelling using RandomUnderSampler dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and RandomUnderSampling sampling\n",
    "columns_to_check = [\n",
    "    'cpd_bronchitis',  \n",
    "    'depression',    \n",
    "    'arthritis',      \n",
    "    'heart_attack',   \n",
    "    'stroke',        \n",
    "    'asthma',       \n",
    "    'diabetes',      \n",
    "    'kidney_disease', \n",
    "    'heart_disease',  \n",
    "    'CD',        \n",
    "    'height',        \n",
    "    'weight'        \n",
    "]\n",
    "\n",
    "X = df.drop(columns=columns_to_check)\n",
    "y = df['CD']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Perform RandomUnderSampler for class imbalance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define columns you want to apply polynomial features to\n",
    "\n",
    "poly_cols = [\n",
    "    'occasion_drink_30days', \n",
    "    'BMI',                \n",
    "    'education',          \n",
    "    'smoker_status',       \n",
    "    'exercise_cat',    \n",
    "    'ave_drink_week',     \n",
    "    'age'              \n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply PolynomialFeatures to selected columns\n",
    "poly_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), poly_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through columns not specified for polynomial features\n",
    ")\n",
    "\n",
    "# Define PCA with n_components=30\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty list to store the results\n",
    "cv_results_list = []\n",
    "train_results_list = []\n",
    "test_results_list = []\n",
    "\n",
    "# Perform cross-validation, train, and test scoring for each classifier\n",
    "for clf_name, clf in classifiers.items():\n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('poly_transformer', poly_transformer),  # Apply polynomial features only to specified columns\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('pca', pca),  # Apply PCA with n_components=30\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_validate(pipeline, X_train_resampled, y_train_resampled, cv=5, scoring=['precision', 'recall', 'f1', 'accuracy'])\n",
    "    cv_results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': cv_scores['test_precision'].mean(),\n",
    "        'Recall': cv_scores['test_recall'].mean(),\n",
    "        'F1': cv_scores['test_f1'].mean(),\n",
    "        'Accuracy': cv_scores['test_accuracy'].mean()\n",
    "    })\n",
    "\n",
    "    # Train scores\n",
    "    pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "    train_preds = pipeline.predict(X_train_resampled)\n",
    "    train_accuracy = accuracy_score(y_train_resampled, train_preds)\n",
    "    train_precision = precision_score(y_train_resampled, train_preds)\n",
    "    train_recall = recall_score(y_train_resampled, train_preds)\n",
    "    train_f1 = f1_score(y_train_resampled, train_preds)\n",
    "    train_results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': train_precision,\n",
    "        'Recall': train_recall,\n",
    "        'F1': train_f1,\n",
    "        'Accuracy': train_accuracy\n",
    "    })\n",
    "\n",
    "    # Test scores\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_preds)\n",
    "    test_precision = precision_score(y_test, test_preds)\n",
    "    test_recall = recall_score(y_test, test_preds)\n",
    "    test_f1 = f1_score(y_test, test_preds)\n",
    "    test_results_list.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': test_precision,\n",
    "        'Recall': test_recall,\n",
    "        'F1': test_f1,\n",
    "        'Accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "# Create DataFrames for cross-validation, train, and test results\n",
    "cv_results_df = pd.DataFrame(cv_results_list)\n",
    "train_results_df = pd.DataFrame(train_results_list)\n",
    "test_results_df = pd.DataFrame(test_results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721112</td>\n",
       "      <td>0.625635</td>\n",
       "      <td>0.669848</td>\n",
       "      <td>0.691868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.668574</td>\n",
       "      <td>0.662672</td>\n",
       "      <td>0.659776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.707584</td>\n",
       "      <td>0.631799</td>\n",
       "      <td>0.667513</td>\n",
       "      <td>0.685358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>0.672770</td>\n",
       "      <td>0.685815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659823</td>\n",
       "      <td>0.644136</td>\n",
       "      <td>0.651829</td>\n",
       "      <td>0.656005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.721112  0.625635  0.669848  0.691868\n",
       "1                 Random Forest   0.656934  0.668574  0.662672  0.659776\n",
       "2     Support Vector Classifier   0.707584  0.631799  0.667513  0.685358\n",
       "3  Gradient Boosting Classifier   0.701772  0.646192  0.672770  0.685815\n",
       "4                       XGBoost   0.659823  0.644136  0.651829  0.656005"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation scores for the 5 baseline models\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.726816</td>\n",
       "      <td>0.628369</td>\n",
       "      <td>0.674017</td>\n",
       "      <td>0.696094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.998401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.659890</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.718593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.751378</td>\n",
       "      <td>0.684788</td>\n",
       "      <td>0.716539</td>\n",
       "      <td>0.729100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.939470</td>\n",
       "      <td>0.961880</td>\n",
       "      <td>0.962768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.726816  0.628369  0.674017  0.696094\n",
       "1                 Random Forest   0.998401  0.998401  0.998401  0.998401\n",
       "2     Support Vector Classifier   0.747671  0.659890  0.701043  0.718593\n",
       "3  Gradient Boosting Classifier   0.751378  0.684788  0.716539  0.729100\n",
       "4                       XGBoost   0.985386  0.939470  0.961880  0.962768"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train scores for the 5 baseline models\n",
    "train_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.581981</td>\n",
       "      <td>0.654795</td>\n",
       "      <td>0.616244</td>\n",
       "      <td>0.722757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.677626</td>\n",
       "      <td>0.571209</td>\n",
       "      <td>0.654145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.566008</td>\n",
       "      <td>0.653881</td>\n",
       "      <td>0.606780</td>\n",
       "      <td>0.711891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.555217</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.605482</td>\n",
       "      <td>0.705061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.494810</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.562992</td>\n",
       "      <td>0.655387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.581981  0.654795  0.616244  0.722757\n",
       "1                 Random Forest   0.493679  0.677626  0.571209  0.654145\n",
       "2     Support Vector Classifier   0.566008  0.653881  0.606780  0.711891\n",
       "3  Gradient Boosting Classifier   0.555217  0.665753  0.605482  0.705061\n",
       "4                       XGBoost   0.494810  0.652968  0.562992  0.655387"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scores for the 5 baseline models\n",
    "test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine resampled features with labels into a single DataFrame\n",
    "undersampled_df = pd.DataFrame(X_train_resampled, columns=X.columns)\n",
    "undersampled_df['CD'] = y_train_resampled\n",
    "\n",
    "# Export the resampled DataFrame to a CSV file\n",
    "undersampled_df.to_csv('../data/undersampled_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Transforming and Modelling using ADASYN oversampled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split and ADASYN sampling\n",
    "\n",
    "columns_to_check2 = [\n",
    "    'cpd_bronchitis', \n",
    "    'depression',    \n",
    "    'arthritis',    \n",
    "    'heart_attack',   \n",
    "    'stroke',       \n",
    "    'asthma',     \n",
    "    'diabetes',      \n",
    "    'kidney_disease', \n",
    "    'heart_disease', \n",
    "    'CD',           \n",
    "    'height',         \n",
    "    'weight'      \n",
    "]\n",
    "\n",
    "X2 = df.drop(columns=columns_to_check2)\n",
    "y2 = df['CD']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)\n",
    "\n",
    "# Perform ADASYN sampling for class imbalance\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X2_train_resampled, y2_train_resampled = adasyn.fit_resample(X2_train, y2_train)\n",
    "\n",
    "# Define columns you want to apply polynomial features to\n",
    "poly_cols = [\n",
    "    'occasion_drink_30days',\n",
    "    'BMI',             \n",
    "    'education',   \n",
    "    'smoker_status',   \n",
    "    'exercise_cat',      \n",
    "    'ave_drink_week',    \n",
    "    'age'              \n",
    "]\n",
    "\n",
    "# Create a ColumnTransformer to apply PolynomialFeatures to selected columns\n",
    "poly_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), poly_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through columns not specified for polynomial features\n",
    ")\n",
    "\n",
    "# Define PCA with n_components=30\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers2 = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Classifier': SVC(),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty list to store the results\n",
    "cv_results_list2 = []\n",
    "train_results_list2 = []\n",
    "test_results_list2 = []\n",
    "\n",
    "# Perform cross-validation, train, and test scoring for each classifier\n",
    "for clf_name, clf in classifiers2.items():\n",
    "    # Create pipeline for each classifier\n",
    "    pipeline2 = Pipeline([\n",
    "        ('poly_transformer', poly_transformer),  # Apply polynomial features only to specified columns\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('pca', pca),  # Apply PCA with n_components=18\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # Cross-validation scores\n",
    "    cv_scores2 = cross_validate(pipeline2, X2_train_resampled, y2_train_resampled, cv=5, scoring=['precision', 'recall', 'f1', 'accuracy'])\n",
    "    cv_results_list2.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': cv_scores2['test_precision'].mean(),\n",
    "        'Recall': cv_scores2['test_recall'].mean(),\n",
    "        'F1': cv_scores2['test_f1'].mean(),\n",
    "        'Accuracy': cv_scores2['test_accuracy'].mean()\n",
    "    })\n",
    "\n",
    "    # Train scores\n",
    "    pipeline2.fit(X2_train_resampled, y2_train_resampled)\n",
    "    train_preds2 = pipeline2.predict(X2_train_resampled)\n",
    "    train_accuracy2 = accuracy_score(y2_train_resampled, train_preds2)\n",
    "    train_precision2 = precision_score(y2_train_resampled, train_preds2)\n",
    "    train_recall2 = recall_score(y2_train_resampled, train_preds2)\n",
    "    train_f1_2 = f1_score(y2_train_resampled, train_preds2)\n",
    "    train_results_list2.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': train_precision2,\n",
    "        'Recall': train_recall2,\n",
    "        'F1': train_f1_2,\n",
    "        'Accuracy': train_accuracy2\n",
    "    })\n",
    "\n",
    "    # Test scores\n",
    "    test_preds2 = pipeline2.predict(X2_test)\n",
    "    test_accuracy2 = accuracy_score(y2_test, test_preds2)\n",
    "    test_precision2 = precision_score(y2_test, test_preds2)\n",
    "    test_recall2 = recall_score(y2_test, test_preds2)\n",
    "    test_f1_2 = f1_score(y2_test, test_preds2)\n",
    "    test_results_list2.append({\n",
    "        'Classifier': clf_name,\n",
    "        'Precision': test_precision2,\n",
    "        'Recall': test_recall2,\n",
    "        'F1': test_f1_2,\n",
    "        'Accuracy': test_accuracy2\n",
    "    })\n",
    "\n",
    "# Create DataFrames for cross-validation, train, and test results\n",
    "cv_results_df2 = pd.DataFrame(cv_results_list2)\n",
    "train_results_df2 = pd.DataFrame(train_results_list2)\n",
    "test_results_df2 = pd.DataFrame(test_results_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.676586</td>\n",
       "      <td>0.591813</td>\n",
       "      <td>0.630894</td>\n",
       "      <td>0.653474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.692310</td>\n",
       "      <td>0.736257</td>\n",
       "      <td>0.713302</td>\n",
       "      <td>0.703899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.683306</td>\n",
       "      <td>0.615556</td>\n",
       "      <td>0.647244</td>\n",
       "      <td>0.664145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.673621</td>\n",
       "      <td>0.632865</td>\n",
       "      <td>0.652263</td>\n",
       "      <td>0.661976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.685593</td>\n",
       "      <td>0.691813</td>\n",
       "      <td>0.688536</td>\n",
       "      <td>0.686485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.676586  0.591813  0.630894  0.653474\n",
       "1                 Random Forest   0.692310  0.736257  0.713302  0.703899\n",
       "2     Support Vector Classifier   0.683306  0.615556  0.647244  0.664145\n",
       "3  Gradient Boosting Classifier   0.673621  0.632865  0.652263  0.661976\n",
       "4                       XGBoost   0.685593  0.691813  0.688536  0.686485"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validation scores for the 5 baseline models\n",
    "cv_results_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.688305</td>\n",
       "      <td>0.618830</td>\n",
       "      <td>0.651721</td>\n",
       "      <td>0.668426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.998128</td>\n",
       "      <td>0.997895</td>\n",
       "      <td>0.998011</td>\n",
       "      <td>0.998006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.725172</td>\n",
       "      <td>0.664444</td>\n",
       "      <td>0.693481</td>\n",
       "      <td>0.705541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.709485</td>\n",
       "      <td>0.681520</td>\n",
       "      <td>0.695222</td>\n",
       "      <td>0.700440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.921201</td>\n",
       "      <td>0.901053</td>\n",
       "      <td>0.911015</td>\n",
       "      <td>0.911756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.688305  0.618830  0.651721  0.668426\n",
       "1                 Random Forest   0.998128  0.997895  0.998011  0.998006\n",
       "2     Support Vector Classifier   0.725172  0.664444  0.693481  0.705541\n",
       "3  Gradient Boosting Classifier   0.709485  0.681520  0.695222  0.700440\n",
       "4                       XGBoost   0.921201  0.901053  0.911015  0.911756"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train scores for the 5 baseline models\n",
    "train_results_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test scores (precision, recall, F1, accuracy) for the baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.632877</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>0.684880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.488678</td>\n",
       "      <td>0.610959</td>\n",
       "      <td>0.543019</td>\n",
       "      <td>0.650419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.550544</td>\n",
       "      <td>0.646575</td>\n",
       "      <td>0.594708</td>\n",
       "      <td>0.700404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.681465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.497405</td>\n",
       "      <td>0.612785</td>\n",
       "      <td>0.549100</td>\n",
       "      <td>0.657870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Precision    Recall        F1  Accuracy\n",
       "0           Logistic Regression   0.530628  0.632877  0.577259  0.684880\n",
       "1                 Random Forest   0.488678  0.610959  0.543019  0.650419\n",
       "2     Support Vector Classifier   0.550544  0.646575  0.594708  0.700404\n",
       "3  Gradient Boosting Classifier   0.524838  0.665753  0.586957  0.681465\n",
       "4                       XGBoost   0.497405  0.612785  0.549100  0.657870"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scores for the 5 baseline models\n",
    "test_results_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine resampled features with labels into a single DataFrame\n",
    "oversampled_df = pd.DataFrame(X2_train_resampled, columns=X2.columns)\n",
    "oversampled_df['CD'] = y2_train_resampled\n",
    "\n",
    "# Export the resampled DataFrame to a CSV file\n",
    "oversampled_df.to_csv('../data/oversampled_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skin_cancer</th>\n",
       "      <th>other_cancer</th>\n",
       "      <th>sex</th>\n",
       "      <th>martial</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>blind</th>\n",
       "      <th>diff_walking</th>\n",
       "      <th>occasion_drink_30days</th>\n",
       "      <th>high_bp</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>one_alc_per_day</th>\n",
       "      <th>binge_drink</th>\n",
       "      <th>ave_drink_week</th>\n",
       "      <th>fruit</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>exercise_cat</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.694303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.731303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22.038567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.100000e+01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.027384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.399184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   skin_cancer  other_cancer  sex  martial  employment_status  blind  \\\n",
       "0            0             1    1        1                  1      0   \n",
       "1            0             0    0        1                  0      0   \n",
       "2            0             0    1        0                  1      0   \n",
       "3            0             0    0        0                  1      0   \n",
       "4            0             0    1        1                  1      0   \n",
       "\n",
       "   diff_walking  occasion_drink_30days  high_bp   age  education  \\\n",
       "0             1                      0        1  10.0          2   \n",
       "1             0                      0        0   3.0          1   \n",
       "2             0                      4        0   1.0          1   \n",
       "3             0                      1        0   6.0          1   \n",
       "4             0                      0        0   3.0          2   \n",
       "\n",
       "   smoker_status  one_alc_per_day  binge_drink  ave_drink_week  fruit  \\\n",
       "0              0                0            0    0.000000e+00      1   \n",
       "1              0                0            0    0.000000e+00      1   \n",
       "2              0                0            0    0.000000e+00      0   \n",
       "3              3                1            0    2.100000e+01      1   \n",
       "4              0                0            0    5.397605e-79      1   \n",
       "\n",
       "   vegetable  exercise_cat  high_cholesterol        BMI  CD  \n",
       "0          1             2                 0  21.694303   1  \n",
       "1          0             1                 0  30.731303   0  \n",
       "2          0             1                 0  22.038567   0  \n",
       "3          0             0                 0  25.027384   0  \n",
       "4          1             0                 0  27.399184   0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations about applying principal component analysis:\n",
    "- While PCA (Principal Component Analysis) is often used for dimensionality reduction, it can sometimes lead to a loss of information, particularly if the original dimensions contain important features for classification. This loss of information can result in decreased accuracy, precision, recall, and F1 score, especially if the reduced dimensions do not capture enough variability in the data to effectively distinguish between classes. \n",
    "- Since we have managed to reduce the number of columns from the original 60 to 30, and managed to retain > 95% of the information. **We have decided to proceed with having n_components = 30 for our analysis.**\n",
    "\n",
    "The main benefits of PCA that made the team come to this conclusion are: \n",
    "1. **Removes Correlated Features:** By converting correlated variables into a set of linearly uncorrelated variables (principal components), PCA helps in removing redundancy in the dataset. This can be particularly useful in models where multicollinearity may be a problem.\n",
    "\n",
    "2. **Optimizes Performance:** Reducing the dimensionality of the data can lead to faster training times and can help in combating the curse of dimensionality, where the feature space becomes so large that the model starts to overfit. By focusing on the most informative aspects of the original data, PCA can lead to more generalized models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Export Model Evaluation Result \n",
    "For offline reference and recording purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling using RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>cv_precision</th>\n",
       "      <th>cv_recall</th>\n",
       "      <th>cv_f1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.721112</td>\n",
       "      <td>0.625635</td>\n",
       "      <td>0.669848</td>\n",
       "      <td>0.691868</td>\n",
       "      <td>0.726816</td>\n",
       "      <td>0.628369</td>\n",
       "      <td>0.674017</td>\n",
       "      <td>0.696094</td>\n",
       "      <td>0.581981</td>\n",
       "      <td>0.654795</td>\n",
       "      <td>0.616244</td>\n",
       "      <td>0.722757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.668574</td>\n",
       "      <td>0.662672</td>\n",
       "      <td>0.659776</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.493679</td>\n",
       "      <td>0.677626</td>\n",
       "      <td>0.571209</td>\n",
       "      <td>0.654145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.707584</td>\n",
       "      <td>0.631799</td>\n",
       "      <td>0.667513</td>\n",
       "      <td>0.685358</td>\n",
       "      <td>0.747671</td>\n",
       "      <td>0.659890</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.718593</td>\n",
       "      <td>0.566008</td>\n",
       "      <td>0.653881</td>\n",
       "      <td>0.606780</td>\n",
       "      <td>0.711891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>0.672770</td>\n",
       "      <td>0.685815</td>\n",
       "      <td>0.751378</td>\n",
       "      <td>0.684788</td>\n",
       "      <td>0.716539</td>\n",
       "      <td>0.729100</td>\n",
       "      <td>0.555217</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.605482</td>\n",
       "      <td>0.705061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659823</td>\n",
       "      <td>0.644136</td>\n",
       "      <td>0.651829</td>\n",
       "      <td>0.656005</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.939470</td>\n",
       "      <td>0.961880</td>\n",
       "      <td>0.962768</td>\n",
       "      <td>0.494810</td>\n",
       "      <td>0.652968</td>\n",
       "      <td>0.562992</td>\n",
       "      <td>0.655387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  cv_precision  cv_recall     cv_f1  \\\n",
       "0           Logistic Regression      0.721112   0.625635  0.669848   \n",
       "1                 Random Forest      0.656934   0.668574  0.662672   \n",
       "2     Support Vector Classifier      0.707584   0.631799  0.667513   \n",
       "3  Gradient Boosting Classifier      0.701772   0.646192  0.672770   \n",
       "4                       XGBoost      0.659823   0.644136  0.651829   \n",
       "\n",
       "   cv_accuracy  train_precision  train_recall  train_f1  train_accuracy  \\\n",
       "0     0.691868         0.726816      0.628369  0.674017        0.696094   \n",
       "1     0.659776         0.998401      0.998401  0.998401        0.998401   \n",
       "2     0.685358         0.747671      0.659890  0.701043        0.718593   \n",
       "3     0.685815         0.751378      0.684788  0.716539        0.729100   \n",
       "4     0.656005         0.985386      0.939470  0.961880        0.962768   \n",
       "\n",
       "   test_precision  test_recall   test_f1  test_accuracy  \n",
       "0        0.581981     0.654795  0.616244       0.722757  \n",
       "1        0.493679     0.677626  0.571209       0.654145  \n",
       "2        0.566008     0.653881  0.606780       0.711891  \n",
       "3        0.555217     0.665753  0.605482       0.705061  \n",
       "4        0.494810     0.652968  0.562992       0.655387  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate cross-validation, train, and test results DataFrames\n",
    "merged_df = pd.concat([cv_results_df.set_index('Classifier'), \n",
    "                       train_results_df.set_index('Classifier'), \n",
    "                       test_results_df.set_index('Classifier')],\n",
    "                      axis=1, keys=['cv', 'train', 'test'])\n",
    "\n",
    "# Reset index to make 'Classifier' a column again\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "merged_df.columns = ['Classifier', \n",
    "                     'cv_precision', 'cv_recall', 'cv_f1', 'cv_accuracy',\n",
    "                     'train_precision', 'train_recall', 'train_f1', 'train_accuracy',\n",
    "                     'test_precision', 'test_recall', 'test_f1', 'test_accuracy']\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "merged_df.to_csv('../data/04_model_evaluation_result_undersampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling using ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>cv_precision</th>\n",
       "      <th>cv_recall</th>\n",
       "      <th>cv_f1</th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.676586</td>\n",
       "      <td>0.591813</td>\n",
       "      <td>0.630894</td>\n",
       "      <td>0.653474</td>\n",
       "      <td>0.688305</td>\n",
       "      <td>0.618830</td>\n",
       "      <td>0.651721</td>\n",
       "      <td>0.668426</td>\n",
       "      <td>0.530628</td>\n",
       "      <td>0.632877</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>0.684880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.692310</td>\n",
       "      <td>0.736257</td>\n",
       "      <td>0.713302</td>\n",
       "      <td>0.703899</td>\n",
       "      <td>0.998128</td>\n",
       "      <td>0.997895</td>\n",
       "      <td>0.998011</td>\n",
       "      <td>0.998006</td>\n",
       "      <td>0.488678</td>\n",
       "      <td>0.610959</td>\n",
       "      <td>0.543019</td>\n",
       "      <td>0.650419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.683306</td>\n",
       "      <td>0.615556</td>\n",
       "      <td>0.647244</td>\n",
       "      <td>0.664145</td>\n",
       "      <td>0.725172</td>\n",
       "      <td>0.664444</td>\n",
       "      <td>0.693481</td>\n",
       "      <td>0.705541</td>\n",
       "      <td>0.550544</td>\n",
       "      <td>0.646575</td>\n",
       "      <td>0.594708</td>\n",
       "      <td>0.700404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.673621</td>\n",
       "      <td>0.632865</td>\n",
       "      <td>0.652263</td>\n",
       "      <td>0.661976</td>\n",
       "      <td>0.709485</td>\n",
       "      <td>0.681520</td>\n",
       "      <td>0.695222</td>\n",
       "      <td>0.700440</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.665753</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.681465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.685593</td>\n",
       "      <td>0.691813</td>\n",
       "      <td>0.688536</td>\n",
       "      <td>0.686485</td>\n",
       "      <td>0.921201</td>\n",
       "      <td>0.901053</td>\n",
       "      <td>0.911015</td>\n",
       "      <td>0.911756</td>\n",
       "      <td>0.497405</td>\n",
       "      <td>0.612785</td>\n",
       "      <td>0.549100</td>\n",
       "      <td>0.657870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  cv_precision  cv_recall     cv_f1  \\\n",
       "0           Logistic Regression      0.676586   0.591813  0.630894   \n",
       "1                 Random Forest      0.692310   0.736257  0.713302   \n",
       "2     Support Vector Classifier      0.683306   0.615556  0.647244   \n",
       "3  Gradient Boosting Classifier      0.673621   0.632865  0.652263   \n",
       "4                       XGBoost      0.685593   0.691813  0.688536   \n",
       "\n",
       "   cv_accuracy  train_precision  train_recall  train_f1  train_accuracy  \\\n",
       "0     0.653474         0.688305      0.618830  0.651721        0.668426   \n",
       "1     0.703899         0.998128      0.997895  0.998011        0.998006   \n",
       "2     0.664145         0.725172      0.664444  0.693481        0.705541   \n",
       "3     0.661976         0.709485      0.681520  0.695222        0.700440   \n",
       "4     0.686485         0.921201      0.901053  0.911015        0.911756   \n",
       "\n",
       "   test_precision  test_recall   test_f1  test_accuracy  \n",
       "0        0.530628     0.632877  0.577259       0.684880  \n",
       "1        0.488678     0.610959  0.543019       0.650419  \n",
       "2        0.550544     0.646575  0.594708       0.700404  \n",
       "3        0.524838     0.665753  0.586957       0.681465  \n",
       "4        0.497405     0.612785  0.549100       0.657870  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate cross-validation, train, and test results DataFrames\n",
    "merged_df1 = pd.concat([cv_results_df2.set_index('Classifier'), \n",
    "                        train_results_df2.set_index('Classifier'), \n",
    "                        test_results_df2.set_index('Classifier')],\n",
    "                        axis=1, keys=['cv', 'train', 'test'])\n",
    "\n",
    "# Reset index to make 'Classifier' a column again\n",
    "merged_df1.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "merged_df1.columns = ['Classifier', \n",
    "                     'cv_precision', 'cv_recall', 'cv_f1', 'cv_accuracy',\n",
    "                     'train_precision', 'train_recall', 'train_f1', 'train_accuracy',\n",
    "                     'test_precision', 'test_recall', 'test_f1', 'test_accuracy']\n",
    "\n",
    "merged_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "merged_df1.to_csv('../data/04_model_evaluation_result_oversampled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Model Evaluation Outcome\n",
    "\n",
    "Based on our problem statement, the task is to identify individuals at high risk for chronic diseases based on their lifestyle data. The significance of the evaluation metrics are as follows: \n",
    "- Accuracy: measures the proportion of correctly classified instances among all instances. In this context, accuracy indicates how well the model predicts both high-risk and not high-risk individuals. \n",
    "- Precision: measures the proportion of true high-risk individuals among all instances classified as high-risk. It focuses on minimizing false positives, i.e., instances wrongly classified as high-risk individuals. In this context, precision indicates the reliability of the model in correctly identifying high-risk individuals.\n",
    "- Recall/ Sensitivity: measures the proportion of true high-risk individuals that are correctly identified by the classifier. It focuses on minimizing false negatives, i.e., high-risk individuals wrongly classified as not high-risk. In this context, recall indicates the ability of the model to capture all actual high-risk individuals.\n",
    "- F1 Score: harmonic mean of precision and recall. It provides a balance between precision and recall, giving equal weight to both metrics. It summarizes the overall performance of the classifier, taking into account both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team has chosen F1 score to be the main metric to focus on for the below reason: \n",
    "\n",
    "**Balanced Trade-Off**  \n",
    "When both false positives and false negatives are equally undesirable:\n",
    "\n",
    "- **False Positive (Wrongly identify an individual as high risk)**: Causes a false alarm, leading to unnecessary stress and resource allocation.\n",
    "- **False Negative (Wrongly identify an individual as low risk)**: Fails to provide timely intervention, potentially leading to adverse health outcomes.\n",
    "\n",
    "**Sensitivity to Class Imbalance**  \n",
    "- Approximately 30% of Asians are medically diagnosed with a chronic disease in our dataset, indicating a significant prevalence that should be taken into account when designing and training predictive models to ensure they are sensitive to class imbalances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Comparison of Sampling Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These are the advantages and disadvantages for both methods:\n",
    "\n",
    "Advantages: \n",
    "- RandomUnderSampler: Generally provides a balanced dataset by randomly removing samples from the majority class.\n",
    "- ADASYN (Adaptive Synthetic Sampling): Generates synthetic samples for the minority class, focusing on areas where the class distribution is sparse.\n",
    "\n",
    "Disadvantages: \n",
    "- RandomUnderSampler: It may discard potentially useful data, leading to loss of information.\n",
    "- ADASYN (Adaptive Synthetic Sampling): May introduce noise into the dataset if not used carefully.\n",
    "\n",
    "Based on the 4 metrics (accuracy, precision, recall and F1 score): \n",
    "\n",
    "| Classifier                     | Metric        | RandomUnderSampler | ADASYN    | Better Sampling Method |\n",
    "|--------------------------------|---------------|--------------------|-----------|------------------------|\n",
    "| Logistic Regression            | Precision     | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Recall        | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | F1-score      | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Accuracy      | Higher             | Lower     | RandomUnderSampler     |\n",
    "| Random Forest                  | Precision     | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Recall        | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | F1-score      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Accuracy      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "| Support Vector Classifier      | Precision     | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Recall        | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | F1-score      | Higher             | Lower     | RandomUnderSampler     |\n",
    "|                                | Accuracy      | Higher             | Lower     | RandomUnderSampler     |\n",
    "| Gradient Boosting Classifier   | Precision     | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Recall        | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | F1-score      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Accuracy      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "| XGBoost                        | Precision     | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Recall        | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | F1-score      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "|                                | Accuracy      | Higher (Train), Lower (Test) | Lower (Train), Higher (Test) | Depends (Train/Test)    |\n",
    "\n",
    "- RandomUnderSampler generally performs better than ADASYN across most classifiers, especially in terms of testing set metrics such as precision, recall, F1-score, and accuracy.\n",
    "- However, the choice between sampling methods may also depend on the specific requirements of the problem and the importance of different evaluation metrics. For instance, if you prioritize generalization performance on unseen data (testing set), RandomUnderSampler might be preferred. However, if you prioritize maximizing recall or sensitivity, ADASYN might be more suitable as it tends to balance the class distribution more effectively.\n",
    "\n",
    "**Overall, based on the comparison, we will take scores from the undersampling with RandomUnderSampler.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Model Evaluation based on Under Sampling\n",
    "\n",
    "Comparison of the baseline models' cross-validation and train scores\n",
    "\n",
    "In general, a smaller difference between the train score and cross-validation score is preferred, as it suggests better generalization performance and less overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.691868               | 0.696094    | 0.004226   |\n",
    "| Random Forest                | 0.662859               | 0.998401    | 0.335542   |\n",
    "| Support Vector Classifier    | 0.685358               | 0.718593    | 0.033235   |\n",
    "| Gradient Boosting Classifier | 0.688669               | 0.730699    | 0.042030   |\n",
    "| XGBoost                      | 0.650410               | 0.963796    | 0.313386   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.721112               | 0.726816    | 0.005704   |\n",
    "| Random Forest                | 0.659726               | 0.999085    | 0.339359   |\n",
    "| Support Vector Classifier    | 0.707471               | 0.747671    | 0.040200   |\n",
    "| Gradient Boosting Classifier | 0.704440               | 0.752753    | 0.048313   |\n",
    "| XGBoost                      | 0.653205               | 0.986814    | 0.333609   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity):\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.625635               | 0.628369    | 0.002734   |\n",
    "| Random Forest                | 0.672686               | 0.997716    | 0.325030   |\n",
    "| Support Vector Classifier    | 0.632027               | 0.659890    | 0.027863   |\n",
    "| Gradient Boosting Classifier | 0.650075               | 0.687072    | 0.036997   |\n",
    "| XGBoost                      | 0.641390               | 0.940155    | 0.298765   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score:\n",
    "\n",
    "| Model                        | Cross-Validation Score | Train Score | Difference |\n",
    "|------------------------------|------------------------|-------------|------------|\n",
    "| Logistic Regression          | 0.669848               | 0.674017    | 0.004169   |\n",
    "| Random Forest                | 0.666116               | 0.998400    | 0.332284   |\n",
    "| Support Vector Classifier    | 0.667590               | 0.701043    | 0.033453   |\n",
    "| Gradient Boosting Classifier | 0.676086               | 0.718414    | 0.042328   |\n",
    "| XGBoost                      | 0.647210               | 0.962920    | 0.315710   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these comparisons, we make the following observations:\n",
    "\n",
    "1. Random Forest: Shows the largest difference between the train scores and cross-validation scores for all four metrics, indicating a high degree of overfitting on the training data.\n",
    "  \n",
    "2. Logistic Regression: Has small negative differences between the train scores and cross-validation scores for accuracy, precision, and F1-score, and a small positive difference for recall. This suggests a slight underfitting on the training data, but with relatively good generalization performance.\n",
    "  \n",
    "3. Support Vector Classifier: Has negative differences between the train scores and cross-validation scores for all four metrics, indicating potential underfitting on the training data, and better performance on the unseen data.\n",
    "  \n",
    "4. Gradient Boosting Classifier: Small to moderate positive differences between the train scores and cross-validation scores for all four metrics, suggesting some degree of overfitting on the training data.  \n",
    "  \n",
    "5. XGBoost: Moderate to large positive differences between the train scores and cross-validation scores for all four metrics, indicating a significant degree of overfitting on the training data.  \n",
    "  \n",
    "A smaller difference between the train score and cross-validation score suggests better generalization performance. Models with larger positive differences, like the Random Forest and XGBoost models, may be overfitting the training data, while models with negative differences or small positive differences, like the Logistic Regression and Support Vector Classifier models, tend to generalize better or may be slightly underfitting the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the baseline models' train and test scores\n",
    "\n",
    "In general, a smaller difference between the train score and test score is preferred, as it suggests better generalization performance and less overfitting or underfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.696094    | 0.722757   | -0.026663  |\n",
    "| Random Forest                | 0.998401    | 0.647004   | 0.351397   |\n",
    "| Support Vector Classifier    | 0.718593    | 0.711891   | 0.006702   |\n",
    "| Gradient Boosting Classifier | 0.730699    | 0.705992   | 0.024707   |\n",
    "| XGBoost                      | 0.963796    | 0.656007   | 0.307789   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision:\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.726816    | 0.581981   | 0.144835   |\n",
    "| Random Forest                | 0.999085    | 0.486399   | 0.512686   |\n",
    "| Support Vector Classifier    | 0.747671    | 0.566008   | 0.181663   |\n",
    "| Gradient Boosting Classifier | 0.752753    | 0.556402   | 0.196351   |\n",
    "| XGBoost                      | 0.986814    | 0.495400   | 0.491414   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity):\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.628369    | 0.654795   | -0.026426  |\n",
    "| Random Forest                | 0.997716    | 0.685845   | 0.311871   |\n",
    "| Support Vector Classifier    | 0.659890    | 0.653881   | 0.006009   |\n",
    "| Gradient Boosting Classifier | 0.687072    | 0.666667   | 0.020405   |\n",
    "| XGBoost                      | 0.940155    | 0.639269   | 0.300886   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score:\n",
    "\n",
    "| Model                        | Train Score | Test Score | Difference |\n",
    "|------------------------------|-------------|------------|------------|\n",
    "| Logistic Regression          | 0.674017    | 0.616244   | 0.057773   |\n",
    "| Random Forest                | 0.998400    | 0.569155   | 0.429245   |\n",
    "| Support Vector Classifier    | 0.701043    | 0.606780   | 0.094263   |\n",
    "| Gradient Boosting Classifier | 0.718414    | 0.606564   | 0.111850   |\n",
    "| XGBoost                      | 0.962920    | 0.558214   | 0.404706   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these comparisons, we can make the following observations:\n",
    "\n",
    "1. Random Forest: Difference between train scores and test scores are too huge (accuracy: 0.35, precision: 0.512, recall: 0.311, F1-score: 0.429).indicating a high degree of overfitting on the training data.  \n",
    "\n",
    "2. Logistic Regression: Has small negative differences between the train and test scores for accuracy (-0.02) and recall (-0.03), and positive differences for precision (0.144) and F1-score (0.057). This suggests relatively good generalization performance overall compared to model such as Random Forest.\n",
    "  \n",
    "3. Support Vector Classifier: Positive differences between the train and test scores for all four metrics (accuracy: 0.0067, precision: 0.181, recall: 0.006, F1-score: 0.09). This suggests relatively good generalization performance overall compared to model such as Random Forest.\n",
    "\n",
    "4. Gradient Boosting Classifier: Shows positive differences between the train and test scores for all four metrics (accuracy: 0.024, precision: 0.196, recall: 0.02, F1-score: 0.111). This suggests relatively good generalization performance overall.  \n",
    "    \n",
    "5. XGBoost: Large positive differences between the train and test scores for all four metrics (accuracy: 0.3, precision: 0.49141, recall: 0.3, F1-score: 0.404). Indicate a significant degree of overfitting on the training data.\n",
    "\n",
    "In summary, a smaller difference between the train score and test score is preferred, as it suggests better generalization performance and less overfitting or underfitting. Models with larger positive differences, like the Random Forest and XGBoost models in this case, are likely overfitting the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "At the end of this notebook, we have decided on the following: \n",
    "1. Use PCA with n_components = 30 to reduce our model training time while retaining more than 95% of our information by using explained variance analysis.\n",
    "2. We have tested out both undersampling and oversampling methods. Both produced similar results with undersampling having slight better test scores throughout. It is then a clear choice to use undersampling since undersampling do not artifically increases the train set which in turn increases model training time.\n",
    "3. We did a quick baselining of the various models and have decided to go with Logistic Regression and SVC to hypertune. The other models either see severe overfitting or have lower F1 scores. \n",
    "\n",
    "In the next notebook, we will hypertune both Logistic Regression and SVC to determine which will be used for our classification model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation Scores for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Create a list of model names\n",
    "models = merged_df['Classifier'].tolist()\n",
    "\n",
    "# Extract the cross-validation scores for each metric\n",
    "cv_scores = merged_df[['cv_accuracy', 'cv_precision', 'cv_recall', 'cv_f1']].values\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the bar width and positions\n",
    "bar_width = 0.15\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "# Loop through each model and create a bar for each metric\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(r + i * bar_width, cv_scores[i] * 100, bar_width, label=model)\n",
    "    for j, score in enumerate(cv_scores[i]):\n",
    "        ax.text(r[j] + i * bar_width, score * 100 + 1, '{:.2f}'.format(score * 100), ha='center', fontsize=6)\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(r + bar_width * 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Score (%)')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Metric')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(45, 75)  # Adjust the limits as needed\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Cross-Validation Scores for Baseline Models')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of comparison of the 4 metrics for the 5 baseline models:\n",
    "- Accuracy:\n",
    "For accuracy, Logistic Regression performs the best with a score of around 69.19%, followed closely by Gradient Boosting Classifier at around 68.58%.\n",
    "\n",
    "- Precision:\n",
    "In terms of precision, Logistic Regression achieves the highest score of approximately 72.11%, while Random Forest and XGBoost have relatively lower scores of around 65.69% and 65.98%, respectively.\n",
    "\n",
    "- Recall:\n",
    "For recall, Random Forest has the highest score of around 66.86%, followed by Gradient Boosting Classifier at around 64.62%. Logistic Regression and Support Vector Classifier have slightly lower recall scores.\n",
    "\n",
    "- F1 Score:\n",
    "The F1 scores, which combine precision and recall, show Gradient Boosting Classifier performing the best with a score of around 67.28%, closely followed by Logistic Regression at around 66.98%.\n",
    "\n",
    "Gradient Boosting Classifier appears to be the most consistent performer, achieving high scores in accuracy, precision and F1 scores, while also having a competitive recall score. It is followed closely by Logistic Regression which has the highest scores in accuracy and precision and competitive F1 scores. Support Vector Classifier performs well in accuracy and precision but has lower recall scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Scores for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Create a list of model names\n",
    "models = merged_df['Classifier'].tolist()\n",
    "\n",
    "# Extract the cross-validation scores for each metric\n",
    "cv_scores = merged_df[['train_accuracy', 'train_precision', 'train_recall', 'train_f1']].values\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the bar width and positions\n",
    "bar_width = 0.15\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "# Loop through each model and create a bar for each metric\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(r + i * bar_width, cv_scores[i] * 100, bar_width, label=model)\n",
    "    for j, score in enumerate(cv_scores[i]):\n",
    "        ax.text(r[j] + i * bar_width, score * 100 + 1, '{:.2f}'.format(score * 100), ha='center', fontsize=6)\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(r + bar_width * 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Score (%)')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Metric')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(40, 105)  # Adjust the limits as needed\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Train Scores for Baseline Models')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of comparison of the 4 metrics for the 5 baseline models:\n",
    "- Accuracy:\n",
    "For accuracy, 2 models, namely Random Forest and XGBoost perform exceptionally well on the training data, with scores ranging from around 99.84% for Random Forest to around 96.28% for XGBoost. The other 3 models have lower accuracy ranging from 69.61% to 72.91%.\n",
    "\n",
    "- Precision:\n",
    "In terms of precision, it follows similar trend with accuracy. Random Forest and XGBoost perform exceptionally well on the training data, with scores ranging from 99.84% for Random Forest to 98.54% for XGBoost. The other 3 models have lower accuracy ranging from 72.68% to 75.14%.\n",
    "\n",
    "- Recall:\n",
    "For recall, Random Forest and XGBoost again perform the best, with scores around 99.84% and 93.95%, respectively. Logistic Regression and Support Vector Classifier have lower recall scores of around 62.84% and 65.99%, respectively.\n",
    "\n",
    "- F1 Score:\n",
    "The F1 scores, which combine precision and recall, show a similar pattern. Random Forest and XGBoost have the highest F1 scores of around 99.84% and 96.19%, respectively, while Logistic Regression and Support Vector Classifier have lower F1 scores of around 67.40% and 70.10%, respectively.\n",
    "\n",
    "It is important to note that these scores are obtained on the training data, which means they may not accurately reflect the models' performance on unseen data due to potential overfitting. However, the high scores across most models and metrics suggest that the models are able to learn the patterns in the training data effectively.\n",
    "\n",
    "Random Forest and XGBoost appear to be the top performers on the training data, achieving high scores across all metrics. Logistic Regression and Support Vector Classifier, while still lag behind the two leader in the 4 metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scores for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of metrics\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Create a list of model names\n",
    "models = merged_df['Classifier'].tolist()\n",
    "\n",
    "# Extract the cross-validation scores for each metric\n",
    "cv_scores = merged_df[['test_accuracy', 'test_precision', 'test_recall', 'test_f1']].values\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the bar width and positions\n",
    "bar_width = 0.15\n",
    "r = np.arange(len(metrics))\n",
    "\n",
    "# Loop through each model and create a bar for each metric\n",
    "for i, model in enumerate(models):\n",
    "    ax.bar(r + i * bar_width, cv_scores[i] * 100, bar_width, label=model)\n",
    "    for j, score in enumerate(cv_scores[i]):\n",
    "        ax.text(r[j] + i * bar_width, score * 100 + 1, '{:.2f}'.format(score * 100), ha='center', fontsize=6)\n",
    "\n",
    "# Set the x-axis tick labels\n",
    "ax.set_xticks(r + bar_width * 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "\n",
    "# Set the y-axis label\n",
    "ax.set_ylabel('Score (%)')\n",
    "\n",
    "# Set the x-axis label\n",
    "ax.set_xlabel('Metric')\n",
    "\n",
    "# Rotate the x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set the y-axis limits\n",
    "ax.set_ylim(40, 75)  # Adjust the limits as needed\n",
    "\n",
    "# Add a title\n",
    "ax.set_title('Test Scores for Baseline Models')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(bbox_to_anchor=(0.5, -0.15), loc='upper center', ncol=5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of comparison of the 4 metrics for the 5 baseline models:\n",
    "- Accuracy:\n",
    "In terms of accuracy, Logistic Regression performs the best with a score of around 72.28%, followed by Support Vector Classifier at around 71.19%. Random Forest and XGBoost have lower accuracy scores at 65.41% and 65.54% respectively.\n",
    "\n",
    "- Precision:\n",
    "For precision, the scores are the lowest for all 4 models compared to other metrics. Logistic Regression achieves the highest score of around 58.20%, closely followed by Support Vector Classifier at around 56.60%. Random Forest and XGBoost have lower precision scores of around 49.37% and 49.48%, respectively.\n",
    "\n",
    "- Recall:\n",
    "In terms of recall, the scores do not differ greatly among the models. Random Forest performs the best with a score of around 67.76%, followed by Gradient Boosting Classifier at around 66.58%.\n",
    "\n",
    "- F1 Score:\n",
    "The F1 scores, which combine precision and recall is the next lower score after precision. Logistic Regression is the top performer with a score of around 61.62%, followed by Support Vector Classifier at around 60.68%. Random Forest and XGBoost have lower F1 scores of around 57.12% and 56.30%, respectively.\n",
    "\n",
    "Overall, Logistic Regression and Support Vector Classifier appear to be the strongest performers on the test set, with Logistic Regression having slightly higher scores in accuracy, and F1, while Support Vector Classifier leads in recall.\n",
    "\n",
    "It's important to note that the test scores are generally lower than the training scores, which is expected due to the potential overfitting of the models on the training data. The drop in performance from training to test sets highlights the importance of evaluating models on unseen data to assess their generalization capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
