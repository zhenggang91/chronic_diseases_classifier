{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 4 - Unveiling Chronic Disease in Singaporean Lifestyle\n",
    "\n",
    "> Authors: Chung Yau, Gilbert, Han Kiong, Zheng Gang\n",
    "---\n",
    "\n",
    "**Problem Statement:**  \n",
    "In Singapore, the increasing prevalence of chronic diseases presents a pressing public health concern, underscoring the need for proactive intervention strategies. \n",
    "\n",
    "How can we identify individuals at high risk for chronic diseases based on their behavioral habits? By doing so, we can enable early detection and provide recommendations, fostering a proactive approach to preventing various chronic diseases.\n",
    "\n",
    "  \n",
    "**Target Audience:**  \n",
    "Product team in Synapxe, in preparation for Healthier SG 2025 roadmap workshop. \n",
    "\n",
    "These are the notebooks for this project:  \n",
    " 1. `01_Data_Collection_Food.ipynb`  \n",
    " 2. `02_Data_Preprocessing.ipynb`   \n",
    " 3. `03_FeatureEngineering_and_EDA.ipynb`\n",
    " 4. `04_Data_Modelling.ipynb` \n",
    " 5. `05_Hyperparameter_Model Fitting_Evaluation.ipynb`\n",
    " 6. `05a_Model_Pickling.ipynb`\n",
    " 7. `06_Implementation_FoodRecommender.ipynb` \n",
    "\n",
    " ---\n",
    "\n",
    "# This Notebook: 01_Data_Collection\n",
    "There are two sections to this project. We have built a classifier as well as a food recommender.   \n",
    "  \n",
    "**For the classifier:**\n",
    "\n",
    "**Source:** Data sourced from the Behavioral Risk Factor Surveillance System (BRFSS), as detailed on the [CDC's BRFSS Questionnaires page](https://www.cdc.gov/brfss/questionnaires/index.htm).  \n",
    "We chose this dataset as the inputs are comprehensive and of a substantial volume (Combing both 2015 and 2013, we have managed to get more than 10k datapoints for our model training). It is important to note that we have only included data of people with Asian race profile to be more relevant to Singapore. \n",
    "\n",
    "**For the recommender:** \n",
    "\n",
    "The categories and recommended nutrition food profiles are derived from the below webpages:\n",
    "- [HealthHub Dietary Allowances](https://www.healthhub.sg/live-healthy/recommended_dietary_allowances)\n",
    "- [HealthHub Calorie Calculator](https://www.healthhub.sg/programmes/nutrition-hub/tools-and-resources#calorie-calculator)\n",
    "- [HealthHub Protein Importance](https://www.healthhub.sg/live-healthy/why_protein_is_important#:~:text=For%20average%20Singaporean%20adults%20aged,1.2g%2Fkg%20bodyweight%20instead.)\n",
    "- [HealthHub Getting the Fats Right](https://www.healthhub.sg/live-healthy/getting%20the%20fats%20right#:~:text=Fat%20should%20make%20up%20about,if%20one%20is%20not%20mindful.)\n",
    "- [USDA National Agricultural Library](https://www.nal.usda.gov/programs/fnic#:~:text=How%20many%20calories%20are%20in,Facts%20label%20on%20food%20packages.)\n",
    "- [Centrum Singapore - Healthy Diet](https://www.centrum.sg/expert-corner/health-blog/healthy-diet-do-you-follow-dietary-guidelines/)\n",
    "- [HPB National Nutrition Survey 2022 Report](https://www.hpb.gov.sg/docs/default-source/pdf/nns-2022-report.pdf)\n",
    "- [Signos - Sugar Intake for Type 2 Diabetics](https://www.signos.com/blog/how-much-sugar-should-a-type-2-diabetic-have-a-day)\n",
    "- [HealthXchange - Diabetes Glycaemic Index](https://www.healthxchange.sg/diabetes/essential-guide-diabetes/diabetes-glycaemic-index-know)\n",
    "- [NDTV Food - Dividing Calories in Each Meal](https://food.ndtv.com/food-drinks/how-to-divide-calories-in-each-meal-we-help-deconstruct-it-for-you-1750305#:~:text=NIN%20recommends%20dividing%20equal%20portion,the%20total%20calories%20you%20consume.)\n",
    "- [Statistics Canada - Sodium Intake](https://www150.statcan.gc.ca/n1/pub/82-003-x/2006004/article/sodium/4148995-eng.htm)\n",
    "\n",
    "The nutritional profile of the dishes are labelled into their cuisine types manually, and the nutrition values can either be found in the below link in [ObservableHQ - SG Hawker Food Nutrition](https://observablehq.com/@yizhe-ang/sg-hawker-food-nutrition) or manually scrapped from [HPB website](https://focos.hpb.gov.sg/eservices/ENCF/). The rest of this notebook will focus on the code to scrap the needed information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Step 1: Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import requests\n",
    "import selenium\n",
    "import time\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### **Step 2: Scraping**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information from HPB [Energy & Nutrient Composition of Food](https://focos.hpb.gov.sg/eservices/ENCF/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://focos.hpb.gov.sg/eservices/ENCF/'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Datasets Table for Option Value and Food Group Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_group_choice</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-- Select Food Group --</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEREAL AND CEREAL PRODUCTS</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGG AND EGG PRODUCTS</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAST FOODS</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            food_group_choice value\n",
       "0     -- Select Food Group --      \n",
       "1                   BEVERAGES    83\n",
       "2  CEREAL AND CEREAL PRODUCTS    73\n",
       "3        EGG AND EGG PRODUCTS    78\n",
       "4                  FAST FOODS    87"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of food group:\n",
    "food_group = []\n",
    "for item in soup.find('select', {'name' : 'ddlFoodGroup'}).find_all('option'):\n",
    "    # if item.attrs:\n",
    "        # print(item.attrs)\n",
    "    food_group_choice = {\n",
    "        'food_group_choice' : item.text,\n",
    "        'value' : item.attrs['value']\n",
    "    }\n",
    "    food_group.append(food_group_choice)\n",
    "\n",
    "food_group_df = pd.DataFrame(food_group)\n",
    "food_group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Datasets Table for Option Value and Nutrition Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nutrient_choice</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-Select-</td>\n",
       "      <td>All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALA</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-Carotene</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calcium</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carbohydrate</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nutrient_choice value\n",
       "0        -Select-   All\n",
       "1             ALA   199\n",
       "2      B-Carotene   146\n",
       "3         Calcium   163\n",
       "4    Carbohydrate   141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of nutrient\n",
    "nutrient_group = []\n",
    "for item in soup.find('select', {'name' : 'ddlNutrient'}).find_all('option'):\n",
    "    nutrient_group_choice = {\n",
    "        'nutrient_choice' : item.text,\n",
    "        'value' : item.attrs['value']\n",
    "    }\n",
    "    nutrient_group.append(nutrient_group_choice)\n",
    "\n",
    "nutrient_group_df = pd.DataFrame(nutrient_group)\n",
    "nutrient_group_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsing Through the Webpage with Selenium - We use selenium function to automate the browsing process to get the information from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to extract information from website with Beautiful Soup\n",
    "def scrape(webpage, food_group_name, nutrient_type_name):\n",
    "    #instantiate Beautiful Soup\n",
    "    soup = BeautifulSoup(webpage)\n",
    "\n",
    "    table_data = []\n",
    "    for row in soup.find('table', class_ = 'gridviewlist').find_all('tr'):\n",
    "        row_data = []\n",
    "        cells = row.find_all('td')\n",
    "        for index in range(len(cells)):\n",
    "            if len(cells) > 7: \n",
    "                row_data = {\n",
    "                    'food_name' : cells[1].text,\n",
    "                    'food_group' : cells[2].text,\n",
    "                    'food_sub_group': cells[3].text,\n",
    "                    'serving_measure': cells[4].text,\n",
    "                    'nutrient' : cells[5].text,\n",
    "                    f'{cells[5].text}_amount' : cells[6].text,\n",
    "                    'nutrient_unit' : cells[7].text\n",
    "                }\n",
    "        if row_data != []:\n",
    "            \n",
    "            table_data.append(row_data)\n",
    "\n",
    "    df = pd.DataFrame(table_data)\n",
    "\n",
    "    #export file to csv\n",
    "    df.to_csv(f'../data/{food_group_name}_{nutrient_type_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to browse webpage\n",
    "def page_driver(food_group_value, food_group_name,nutrient_value,nutrient_group_name):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://focos.hpb.gov.sg/eservices/ENCF/')\n",
    "    #Food Group dropdown selection\n",
    "    select_food_group_element = driver.find_element(By.NAME, 'ddlFoodGroup')\n",
    "    select_food_group = Select(select_food_group_element)\n",
    "    #select type of Food Group from dropdown\n",
    "    select_food_group.select_by_value(food_group_value) \n",
    "\n",
    "    #Nutrient dropdown selection\n",
    "    select_nutrient_element = driver.find_element(By.NAME, 'ddlNutrient')\n",
    "    select_nutrient = Select(select_nutrient_element)\n",
    "    \n",
    "    #select type of nutrient from dropdown\n",
    "    select_nutrient.select_by_value(nutrient_value) \n",
    "\n",
    "    #trigger search button to display the table\n",
    "    find_search = driver.find_element(By.XPATH,'//*[@id=\"btnSearch\"]')\n",
    "    find_search.click()\n",
    "\n",
    "    WebDriverWait(driver,10).until(EC.presence_of_element_located((By.CLASS_NAME,'gridviewlist')))\n",
    "\n",
    "    #save browsed page\n",
    "    page_source = driver.page_source\n",
    "    time.sleep(10)\n",
    "    return scrape(page_source, food_group_name = food_group_name, nutrient_type_name = nutrient_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Datasets of Food with the Nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and sugar\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[34]['value'],\n",
    "            nutrient_group_df.iloc[34]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and carbohydrate\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[4]['value'],\n",
    "            nutrient_group_df.iloc[4]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and total fat\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[38]['value'],\n",
    "            nutrient_group_df.iloc[38]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and cholesterol\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[6]['value'],\n",
    "            nutrient_group_df.iloc[6]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and sodium\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[32]['value'],\n",
    "            nutrient_group_df.iloc[32]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and protein\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[27]['value'],\n",
    "            nutrient_group_df.iloc[27]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and calories\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[9]['value'],\n",
    "            nutrient_group_df.iloc[9]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixed ethnic dishes, and glycemic index\n",
    "page_driver(food_group_df.iloc[11]['value'],\n",
    "            food_group_df.iloc[11]['food_group_choice'],\n",
    "            nutrient_group_df.iloc[12]['value'],\n",
    "            nutrient_group_df.iloc[12]['nutrient_choice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this section, we would have created 8 csv with the below names that we will need to proceed with the cleaning in the next section.   \n",
    "The csv file can be found in the data folder in the form of `{food_group_name}_{nutrient_type_name}.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Step 3: Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSV file saved in previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Protein.csv')\n",
    "df2 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Total fat.csv')\n",
    "df3 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Carbohydrate.csv')\n",
    "df4 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Cholesterol.csv')\n",
    "df5 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Sodium.csv')\n",
    "df6 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Sugar.csv')\n",
    "df7 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Glycemic index.csv')\n",
    "df8 = pd.read_csv('../data/MIXED ETHNIC DISHES, ANALYZED IN SINGAPORE_Energy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all datasets into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all datasets \n",
    "df = pd.concat([df1, df2],axis = 0)\n",
    "df = pd.concat([df,df3], axis = 0)\n",
    "df = pd.concat([df,df4], axis = 0)\n",
    "df = pd.concat([df,df5], axis = 0)\n",
    "df = pd.concat([df,df6], axis = 0)\n",
    "df = pd.concat([df,df7], axis = 0)\n",
    "df = pd.concat([df,df8], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 0\n",
       "food_name                  0\n",
       "food_group                 0\n",
       "food_sub_group             0\n",
       "serving_measure            0\n",
       "nutrient                   0\n",
       "Protein_amount           689\n",
       "nutrient_unit              0\n",
       "Total fat_amount         689\n",
       "Carbohydrate_amount      689\n",
       "Cholesterol_amount       689\n",
       "Sodium_amount            689\n",
       "Sugar_amount             689\n",
       "Glycemic index_amount    763\n",
       "Energy_amount            689\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicated food names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicated food name\n",
    "df.drop_duplicates(subset= ['food_name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset index\n",
    "df = df.reset_index(drop = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are many null data from the original dataset. We will proceed to scrap again but this time using the code to seek for the relevant nutrional values in the dataset instead of obtaining them just from the table presented as we found that pagination does not work for the website we intend to scrap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Protein_amount', 'Total fat_amount', 'Carbohydrate_amount',\n",
       "       'Cholesterol_amount', 'Sodium_amount', 'Sugar_amount',\n",
       "       'Glycemic index_amount', 'Energy_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['nutrient_unit']).columns[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert column nutrient type to value for scraping purpose\n",
    "def option_value(column):\n",
    "    if 'Protein' in column:\n",
    "        value = '135'\n",
    "    elif \"Total fat\" in column: \n",
    "        value = \"136\"\n",
    "    elif 'Carbohydrate' in column:\n",
    "        value = '141'\n",
    "    elif 'Cholesterol' in column:\n",
    "        value = '140'\n",
    "    elif 'Energy' in column:\n",
    "        value = '134'\n",
    "    elif 'Sodium' in column:\n",
    "        value = '160'\n",
    "    elif 'Glycemic index' in column:\n",
    "        value = '219'\n",
    "    elif 'Sugar' in column:\n",
    "        value = \"143\"\n",
    "\n",
    "    return value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping function\n",
    "def scrape(webpage):\n",
    "    soup = BeautifulSoup(webpage)\n",
    "    try:\n",
    "        for row in soup.find('table', class_ = 'gridviewlist').find_all('tr'):\n",
    "            row_data = []\n",
    "            cells = row.find_all('td')\n",
    "            for item in cells:\n",
    "                row_data.append(item.text.strip())\n",
    "        print(\"Success\")\n",
    "        return row_data[4]\n",
    "    except:\n",
    "        print(\"No Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing web with Selenium\n",
    "def page_driver(data, column_number, index): \n",
    "    #instantiate selenium\n",
    "    driver = webdriver.Chrome()\n",
    "    #fetch webpage from the given link\n",
    "    driver.get('https://focos.hpb.gov.sg/eservices/ENCF/')\n",
    "\n",
    "    #find Food Name textbox\n",
    "    find_food_name = driver.find_element(By.NAME, 'txtFoodName')\n",
    "    #input values into textbox\n",
    "    enter_food_name = find_food_name.send_keys(data['food_name'][index])\n",
    "\n",
    "    #Nutrient dropdown selection\n",
    "    select_nutrient_element = driver.find_element(By.NAME, 'ddlNutrient')\n",
    "    select_nutrient = Select(select_nutrient_element)\n",
    "    #select type of nutrient from dropdown\n",
    "    select_nutrient.select_by_value(option_value(data.columns[column_number])) \n",
    "\n",
    "    #trigger search button to display the table\n",
    "    find_search = driver.find_element(By.XPATH,'//*[@id=\"btnSearch\"]')\n",
    "    find_search.click()\n",
    "\n",
    "    # WebDriverWait(driver,5).until(EC.presence_of_element_located((By.CLASS_NAME,'gridviewlist')))\n",
    "    #save browsed page\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    return scrape(page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['nutrient'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of column name and its index\n",
    "column_list = {'Protein_amount' : 5,\n",
    "               'Total fat_amount' : 7,\n",
    "               'Carbohydrate_amount' : 8,\n",
    "               'Cholesterol_amount' : 9,\n",
    "               'Sodium_amount': 10,\n",
    "               'Sugar_amount': 11,\n",
    "               'Glycemic index_amount' : 12,\n",
    "               'Energy_amount' : 13\n",
    "}\n",
    "\n",
    "#run loop to fill in nan values by scraping value from source\n",
    "for column_name, column_index in column_list.items():\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row[column_name]):\n",
    "            replacement_value = page_driver(df,column_index,index)\n",
    "\n",
    "            df.at[index, column_name] = replacement_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 0\n",
       "food_name                  0\n",
       "food_group                 0\n",
       "food_sub_group             0\n",
       "serving_measure            0\n",
       "Protein_amount            22\n",
       "nutrient_unit              0\n",
       "Total fat_amount          72\n",
       "Carbohydrate_amount      484\n",
       "Cholesterol_amount       499\n",
       "Sodium_amount            514\n",
       "Sugar_amount             520\n",
       "Glycemic index_amount    545\n",
       "Energy_amount            519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Step 4: Export**\n",
    "\n",
    "We now export the scrapped data for manually labelling and cleaning the development of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/food_data_sg.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
