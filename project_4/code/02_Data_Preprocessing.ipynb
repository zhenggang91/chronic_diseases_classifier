{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 4 - Unveiling Chronic Disease in Singaporean Lifestyle\n",
    "\n",
    "> Authors: Chung Yau, Gilbert, Han Kiong, Zheng Gang\n",
    "---\n",
    "\n",
    "**Problem Statement:**  \n",
    "In Singapore, the increasing prevalence of chronic diseases presents a pressing public health concern, underscoring the need for proactive intervention strategies. \n",
    "\n",
    "How can we identify individuals at high risk for chronic diseases based on their behavioral habits? By doing so, we can enable early detection and provide recommendations, fostering a proactive approach to preventing various chronic diseases.\n",
    "\n",
    "  \n",
    "**Target Audience:**  \n",
    "Product team in Synapxe, in preparation for Healthier SG 2025 roadmap workshop. \n",
    "\n",
    "These are the notebooks for this project:  \n",
    " 1. `01_Data_Collection_Food.ipynb`  \n",
    " 2. `02_Data_Preprocessing.ipynb`   \n",
    " 3. `03_FeatureEngineering_and_EDA.ipynb`\n",
    " 4. `04_Data_Modelling.ipynb` \n",
    " 5. `05_Hyperparameter_Model Fitting_Evaluation.ipynb`\n",
    " 6. `05a_Model_Pickling.ipynb`\n",
    " 7. `06_Implementation_FoodRecommender.ipynb` \n",
    "\n",
    " ---\n",
    "\n",
    "# This Notebook: 02_Data_Preprocessing\n",
    "- We will focus on cleaning the dataset and dropping irrelevant features.\n",
    "- The expected output of this notebook will be a file that is suitable for upcoming EDA (Exploratory Data Analysis) and modeling in subsequent notebooks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports necessary libraries for data manipulation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas to read the data file csv which was zipped.\n",
    "dataframe = pd.read_csv(\"../data/2015.zip\", compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENUM</th>\n",
       "      <th>...</th>\n",
       "      <th>_PAREC1</th>\n",
       "      <th>_PASTAE1</th>\n",
       "      <th>_LMTACT1</th>\n",
       "      <th>_LMTWRK1</th>\n",
       "      <th>_LMTSCL1</th>\n",
       "      <th>_RFSEAT2</th>\n",
       "      <th>_RFSEAT3</th>\n",
       "      <th>_FLSHOT6</th>\n",
       "      <th>_PNEUMO2</th>\n",
       "      <th>_AIDTST3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01292015'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'29'</td>\n",
       "      <td>b'2015'</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01202015'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'20'</td>\n",
       "      <td>b'2015'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02012015'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'2015'</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01142015'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'14'</td>\n",
       "      <td>b'2015'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01142015'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'14'</td>\n",
       "      <td>b'2015'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>2.015000e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE         SEQNO  \\\n",
       "0     1.0     1.0  b'01292015'  b'01'  b'29'  b'2015'    1200.0  2.015000e+09   \n",
       "1     1.0     1.0  b'01202015'  b'01'  b'20'  b'2015'    1100.0  2.015000e+09   \n",
       "2     1.0     1.0  b'02012015'  b'02'  b'01'  b'2015'    1200.0  2.015000e+09   \n",
       "3     1.0     1.0  b'01142015'  b'01'  b'14'  b'2015'    1100.0  2.015000e+09   \n",
       "4     1.0     1.0  b'01142015'  b'01'  b'14'  b'2015'    1100.0  2.015000e+09   \n",
       "\n",
       "           _PSU  CTELENUM  ...  _PAREC1  _PASTAE1  _LMTACT1  _LMTWRK1  \\\n",
       "0  2.015000e+09       1.0  ...      4.0       2.0       1.0       1.0   \n",
       "1  2.015000e+09       1.0  ...      2.0       2.0       3.0       3.0   \n",
       "2  2.015000e+09       1.0  ...      9.0       9.0       9.0       9.0   \n",
       "3  2.015000e+09       1.0  ...      4.0       2.0       1.0       1.0   \n",
       "4  2.015000e+09       1.0  ...      4.0       2.0       1.0       1.0   \n",
       "\n",
       "   _LMTSCL1  _RFSEAT2  _RFSEAT3  _FLSHOT6  _PNEUMO2  _AIDTST3  \n",
       "0       1.0       1.0       1.0       NaN       NaN       1.0  \n",
       "1       4.0       2.0       2.0       NaN       NaN       2.0  \n",
       "2       9.0       9.0       9.0       9.0       9.0       NaN  \n",
       "3       1.0       1.0       1.0       NaN       NaN       9.0  \n",
       "4       1.0       1.0       1.0       NaN       NaN       1.0  \n",
       "\n",
       "[5 rows x 330 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441456, 330)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 330 columns in the dataset. We will drop irrelevant features and focus on features that we wish to investigate in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Dropping irrelevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be focusing on the following categories of features for our analysis:   \n",
    "1. Alcohol consumption habits, \n",
    "2. Existing health conditions, \n",
    "3. User demographics,  \n",
    "4. Physical activity habits,   \n",
    "5. Smoking habits, and   \n",
    "6. Dietary habits.\n",
    "\n",
    "Due to the sheer volume of columns. The team finds the need to manually sieve through feature by feature to determine the suitability of the columns. For specifics of how we determine which column to drop can be found in this gsheet. The columns that are marked `\"To include == Y\"` are those that are identified as the candidate features. \n",
    "https://docs.google.com/spreadsheets/d/1jVtQ1TYKtLA9SFqdjPmhYl1fqRrUywjBrI5U5cKXbBo/edit#gid=1776346838. A copy of the analysis file (`Variable list.xlsx`) is available in the data/ folder.\n",
    "\n",
    "In the data preprocessing, the features that have high percentage (i.e. 5%) of empty values, as well as column from the column pair with strong correlation ( correlation coefficient > 0.8) will be dropped. The filtered features will then be cross checked against the candidate features from the analysis. Discrepancies, if any, will be dealt with accordingly. \n",
    "\n",
    "BLANK in this dataset implies that the data is either missing or not asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "We will first proceed to drop features with more than 5% of the respondants (20,000 missing values) for our first cut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = dataframe.isnull().sum()  \n",
    "sorted_null_counts = null_counts.sort_values(ascending=False) \n",
    "sorted_null_counts_df = pd.DataFrame({\n",
    "    \"feature\": sorted_null_counts.index,\n",
    "    \"null_count\": sorted_null_counts.values  \n",
    "})\n",
    "\n",
    "filtered_sorted_null_counts_df = sorted_null_counts_df[sorted_null_counts_df[\"null_count\"] >= 20000]\n",
    "filtered_sorted_null_counts_df[\"feature\"].values\n",
    "columns_to_drop_v1 = filtered_sorted_null_counts_df[\"feature\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v1 = dataframe.drop(columns = columns_to_drop_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441456, 121)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 121 columns. we now manually assess the features and drop those that are not of our interest above or we already see that there are redundant features that are already represented by other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_v2 = [\n",
    "    'USENOW3', 'INTERNET', 'INCOME2', '_LMTACT1', '_LMTWRK1', '_LMTSCL1', '_STRWT', 'QSTLANG', 'VETERAN3', 'CHILDREN',\n",
    "    'MEDCOST', 'CHECKUP1', 'HLTHPLN1', '_STATE', 'FMONTH', 'IDATE', 'IMONTH', 'IDAY', 'IYEAR', 'DISPCODE', 'SEQNO',\n",
    "    '_PSU', 'PERSDOC2', 'RENTHOM1', 'PCDMDECN', 'QSTVER', '_STSTR', '_RAWRAKE', '_WT2RAKE', '_DUALUSE', '_HCVU651',\n",
    "    '_CHOLCHK', '_CHLDCNT', '_MISFRTN', '_MISVEGN', '_FRTRESP', '_VEGRESP', '_FRUITEX', '_VEGETEX', 'MAXVO2_', 'FC60_',\n",
    "    'PAMISS1_', '_PACAT1', '_PASTRNG', '_PAREC1', '_PASTAE1', '_RFSEAT2', '_RFSEAT3', 'EXACTOT1', 'EXACTOT2', '_INCOMG', '_PA300R2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v2 = dataframe_v1.drop(columns = columns_to_drop_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441456, 69)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with 69 features from the original 330. we now run a correlation analysis to identify columns with correlation more than 0.8. This indicates repeated information and we can further simpilfy our dataset with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs of columns with correlation greater than 0.8\n",
      "      Column 1  Column 2  Correlation\n",
      "866   HAVARTH3  _DRDXAR1     1.000000\n",
      "1295     EDUCA   _EDUCAG     0.979974\n",
      "1432   WEIGHT2   _RFBMI5     0.860003\n",
      "2055  SMOKE100  _SMOKER3     0.802848\n",
      "2731   _PRACE1   _MRACE1     0.998638\n",
      "2942     _RACE  _RACEGR3     0.957102\n",
      "2943     _RACE  _RACE_G1     0.835171\n",
      "3011  _RACEG21  _RACEGR3     0.835251\n",
      "3012  _RACEG21  _RACE_G1     0.883616\n",
      "3081  _RACEGR3  _RACE_G1     0.858784\n",
      "3222  _AGEG5YR    _AGE80     0.976520\n",
      "3223  _AGEG5YR    _AGE_G     0.951450\n",
      "3361    _AGE80    _AGE_G     0.971136\n",
      "3501     HTIN4      HTM4     0.999611\n",
      "3921  DRNKANY5  DROCDY3_     0.916879\n",
      "3922  DRNKANY5  _RFBING5     0.826619\n",
      "3923  DRNKANY5  _DRNKWEK     0.851606\n",
      "3924  DRNKANY5  _RFDRHV5     0.841366\n",
      "3991  DROCDY3_  _RFBING5     0.907486\n",
      "3992  DROCDY3_  _DRNKWEK     0.909973\n",
      "3993  DROCDY3_  _RFDRHV5     0.909930\n",
      "4061  _RFBING5  _DRNKWEK     0.885880\n",
      "4062  _RFBING5  _RFDRHV5     0.888252\n",
      "4131  _DRNKWEK  _RFDRHV5     0.995035\n",
      "4551  _TOTINDA  _PAINDX1     0.809471\n",
      "4552  _TOTINDA  _PA150R2     0.810950\n",
      "4621  _PAINDX1  _PA150R2     0.984800\n",
      "4622  _PAINDX1  _PA30021     0.959706\n",
      "4691  _PA150R2  _PA30021     0.935848\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = dataframe_v2.corr()\n",
    "\n",
    "high_correlation = correlation_matrix[correlation_matrix > 0.5]\n",
    "high_correlation = high_correlation.unstack().reset_index()\n",
    "high_correlation.columns = ['Column 1', 'Column 2', 'Correlation']\n",
    "\n",
    "high_correlation = high_correlation[(high_correlation['Column 1'] != high_correlation['Column 2']) & \n",
    "                                    (high_correlation['Correlation'].notna())]\n",
    "\n",
    "high_correlation = high_correlation.drop_duplicates(subset=['Correlation'])\n",
    "\n",
    "high_correlation = high_correlation[high_correlation['Correlation'] > 0.80]\n",
    "\n",
    "print(\"Pairs of columns with correlation greater than 0.8\")\n",
    "print(high_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, we then drop more features for those which are severely correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_v3 = [\n",
    "    'DIFFALON', 'WEIGHT2', 'BPHIGH4', 'CVDCRHD4', 'HAVARTH3', '_LLCPWT', '_RACEGR3', '_FRT16', '_VEG23', 'BLOODCHO',\n",
    "    '_RFSMOK3', 'HTIN4', 'SMOKE100', 'DIFFDRES', 'DECIDE', 'USEEQUIP', 'QLACTLM2', '_RACE_G1', 'HEIGHT3',\n",
    "    'GENHLTH', 'PHYSHLTH', 'EDUCA', '_MRACE1', '_HISPANC', '_RACEG21', '_AGE65YR', '_AGE80', '_AGE_G', '_RFBMI5',\n",
    "    '_PA30021', '_TOTINDA', 'MENTHLTH', '_LTASTH1', '_CASTHM1', '_ASTHMS1', '_RFHLTH', '_PRACE1', '_PAINDX1', 'DROCDY3_', '_RFDRHV5'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v3 = dataframe_v2.drop(columns = columns_to_drop_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441456, 29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CVDINFR4', 'CVDSTRK3', 'ASTHMA3', 'CHCSCNCR', 'CHCOCNCR', 'CHCCOPD1',\n",
       "       'ADDEPEV2', 'CHCKIDNY', 'DIABETE3', 'SEX', 'MARITAL', 'EMPLOY1',\n",
       "       'BLIND', 'DIFFWALK', 'ALCDAY5', '_RFHYPE5', '_MICHD', '_DRDXAR1',\n",
       "       '_RACE', '_AGEG5YR', 'HTM4', '_EDUCAG', '_SMOKER3', 'DRNKANY5',\n",
       "       '_RFBING5', '_DRNKWEK', '_FRTLT1', '_VEGLT1', '_PA150R2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed to verify whether any discrepancy with the candidate features identified during analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `Variable list - Tentative list.csv` is the analysis of the data based on given data dictionary from the source. A group of columns that are marked \"To include = Y\" are the candidate columns to be used for Features based on our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_candidate = pd.read_csv(\"../data/Variable list - Tentative list.csv\", skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Description</th>\n",
       "      <th>To include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>_SMOKER3</td>\n",
       "      <td>Four-level smoker status: Everyday smoker, Som...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DRNKANY5</td>\n",
       "      <td>Adults who reported having had at least one dr...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>_RFBING5</td>\n",
       "      <td>Binge drinkers (males having five or more drin...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>_RACE</td>\n",
       "      <td>Race/ethnicity categories</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ALCDAY5</td>\n",
       "      <td>During the past 30 days, how many days per wee...</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature                                        Description To include\n",
       "26  _SMOKER3  Four-level smoker status: Everyday smoker, Som...          Y\n",
       "27  DRNKANY5  Adults who reported having had at least one dr...          Y\n",
       "28  _RFBING5  Binge drinkers (males having five or more drin...          Y\n",
       "29     _RACE                          Race/ethnicity categories          Y\n",
       "30   ALCDAY5  During the past 30 days, how many days per wee...          Y"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_candidate.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_list = feature_candidate[feature_candidate['To include'] == 'Y']['Feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the candidate feature, check if the candidate feature is available too in the filtered feature list. If not available, captured in the `candidate_drop`, will be further dealt with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_RFCHOL', 'WTKG3']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_drop = []\n",
    "for candidate in list(candidate_list):\n",
    "    if candidate not in list(dataframe_v3):\n",
    "        candidate_drop.append(candidate)\n",
    "\n",
    "candidate_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that we had intendeded to include  `_RFCHOL` and `WTKG3` in our initial analysis but they were drop. They were dropped due to high number of missing values in the datasets. The team look a deeper look and have decided the on the following:  \n",
    "  \n",
    "`WTKG3` - this defines the weight of the individual and approx 7.5% of the values were missing. The team sees this as an important variable to determine the risk of chronic disease for an individual and have decided to add it into the dataset. The missing values will be imputed with the missing values.   \n",
    " `_RFCHOL` - this defines if the individual has high cholestrol and approx 12.5% of the values were missing. Similarly, this is important and we will include this information while taking missing values as non-declarance of the individual having said condition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add both variables back to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v4 = pd.concat([dataframe_v3, dataframe[\"_RFCHOL\"]], axis = 1)\n",
    "dataframe_v4 = pd.concat([dataframe_v4, dataframe[\"WTKG3\"]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the candidate features identified during analysis of the raw data are available in the filtered features. Analysis outcome was aligned with the feature filtering implemented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, we arrived at the 31 columns for our data cleaning and next steps.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. Merging 2013.csv\n",
    "\n",
    "After the EDA, it was finalized that, out of the 441456 rows of data in the 2015.csv, only 9759 rows of data for \"Asian\" people are relevant for modeling. In order to increase the number of data rows for EDA and modeling, the data in the 2013.csv will be loaded and concatenate with the 2015.csv data. \n",
    "\n",
    "***Reason for choosing 2013.csv***\n",
    "Analysis was performed on the downloaded dataset. There are total of 5 CSV provided by the data source, where every CSV contains the data collected for a particular year. The 5 CSV file, namely 2011.csv, 2012.csv, 2013.csv, 2014.csv and 2015.csv, are therefore the data collected in year 2011, 2012, 2013, 2014 and 2015 respectively. Not all the data columns are identical in the 5 files.   \n",
    "  \n",
    "The analysis report `Variable list - data availability.csv` listed the columns discrepencies among the 31 data columns identified for EDA and modeling, with data columns in 2015.csv as the baseline. From the analysis, 2013.csv has the least column discrepancy, with only 2 columns missing. The team decided, therefore, to concatenate the data in 2013.csv, so that additional 9510 records (for Asian people) are added to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>FMONTH</th>\n",
       "      <th>IDATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>IDAY</th>\n",
       "      <th>IYEAR</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEQNO</th>\n",
       "      <th>_PSU</th>\n",
       "      <th>CTELENUM</th>\n",
       "      <th>...</th>\n",
       "      <th>_AGE80</th>\n",
       "      <th>_IMPEDUC</th>\n",
       "      <th>_IMPMRTL</th>\n",
       "      <th>_IMPHOME</th>\n",
       "      <th>RCSBRAC1</th>\n",
       "      <th>RCSRACE1</th>\n",
       "      <th>RCHISLA1</th>\n",
       "      <th>RCSBIRTH</th>\n",
       "      <th>TYPEINDS</th>\n",
       "      <th>TYPEWORK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01092013'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'09'</td>\n",
       "      <td>b'2013'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01192013'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'19'</td>\n",
       "      <td>b'2013'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01192013'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'19'</td>\n",
       "      <td>b'2013'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01112013'</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>b'11'</td>\n",
       "      <td>b'2013'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'02062013'</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>b'06'</td>\n",
       "      <td>b'2013'</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>2.013001e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "      <td>b''</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 336 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  FMONTH        IDATE IMONTH   IDAY    IYEAR  DISPCODE         SEQNO  \\\n",
       "0     1.0     1.0  b'01092013'  b'01'  b'09'  b'2013'    1100.0  2.013001e+09   \n",
       "1     1.0     1.0  b'01192013'  b'01'  b'19'  b'2013'    1100.0  2.013001e+09   \n",
       "2     1.0     1.0  b'01192013'  b'01'  b'19'  b'2013'    1100.0  2.013001e+09   \n",
       "3     1.0     1.0  b'01112013'  b'01'  b'11'  b'2013'    1100.0  2.013001e+09   \n",
       "4     1.0     2.0  b'02062013'  b'02'  b'06'  b'2013'    1100.0  2.013001e+09   \n",
       "\n",
       "           _PSU  CTELENUM  ...  _AGE80  _IMPEDUC  _IMPMRTL  _IMPHOME  \\\n",
       "0  2.013001e+09       1.0  ...    60.0       6.0       2.0       1.0   \n",
       "1  2.013001e+09       1.0  ...    50.0       5.0       1.0       1.0   \n",
       "2  2.013001e+09       1.0  ...    55.0       6.0       1.0       1.0   \n",
       "3  2.013001e+09       1.0  ...    64.0       4.0       1.0       1.0   \n",
       "4  2.013001e+09       1.0  ...    66.0       6.0       1.0       1.0   \n",
       "\n",
       "   RCSBRAC1  RCSRACE1  RCHISLA1  RCSBIRTH  TYPEINDS  TYPEWORK  \n",
       "0       NaN       b''       b''       b''       b''       b''  \n",
       "1       NaN       b''       b''       b''       b''       b''  \n",
       "2       NaN       b''       b''       b''       b''       b''  \n",
       "3       NaN       b''       b''       b''       b''       b''  \n",
       "4       NaN       b''       b''       b''       b''       b''  \n",
       "\n",
       "[5 rows x 336 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013 = pd.read_csv(\"../data/2013.zip\", compression='zip')\n",
    "df_2013.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491773, 336)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the column discrepancy between 2013 dataset and 2015 dataset. Note that 2015 dateset is the baseline dataset where the 31 columns were identified from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_DRNKWEK', '_MICHD'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_2015df = set(dataframe_v4.columns)\n",
    "columns_2013df = set(df_2013.columns) \n",
    "columns_not_in_2013df = columns_2015df - columns_2013df\n",
    "columns_not_in_2013df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `_DRNKWEK` and `_MICHD` is not in the 2013 dataset. However, there are similar columns within the same year that we can use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_DRNKWEK` : represents the total number of alcoholic beverages consumed per week. It is calculated by taking `AVEDRNK2` * `DROCDY3_` *7. Both `AVEDRNK2`, `DROCDY3_` are present in the 2013 dataset. Thus, we will be able to calculate them. \n",
    "\n",
    "`_MICHD` : represents if the users have coronary heart diesease (CHD) or myocardial infarction (MI). It is possible to derive these information from `CVDINFR4` and `CVDCRHD4`. We will be able to create these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013[\"DROCDY3_\"] = df_2013[\"DROCDY3_\"].map(lambda x : x if x in range(1,900) else 0)\n",
    "df_2013[\"AVEDRNK2\"] = df_2013[\"AVEDRNK2\"].map(lambda x : x if x in range(1,77) else 0)\n",
    "df_2013[\"_DRNKWEK\"] = df_2013[\"AVEDRNK2\"]*df_2013[\"DROCDY3_\"]*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013[\"CVDINFR4\"] = df_2013[\"CVDINFR4\"].map(lambda x : 1 if x == 1 else 0)\n",
    "df_2013[\"CVDCRHD4\"] = df_2013[\"CVDCRHD4\"].map(lambda x : 1 if x == 1 else 0)\n",
    "df_2013[\"_MICHD\"] = df_2013.apply(lambda row: max(row[\"CVDINFR4\"], row[\"CVDCRHD4\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the 31 columns identified in 2015 dataset (in dataframe_v4) to filter out the same columns in 2013 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013_match = df_2013[dataframe_v4.columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(491773, 31)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441456, 31)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final confirm that both 2013 dataset and 2015 dataset has identical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_2015df = set(dataframe_v4.columns)\n",
    "columns_2013df = set(df_2013_match.columns) \n",
    "columns_not_in_2013df = columns_2015df - columns_2013df\n",
    "columns_not_in_2013df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_not_in_2015df = columns_2013df - columns_2015df\n",
    "columns_not_in_2015df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe from 2013 dataset is now confirm matching the dataset from 2015. Ready to concatenate both dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: The na values in the respective columns will be dealt with in the next section, altogether after concatenate the two dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933229, 31)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_2013_2015 = pd.concat([dataframe_v4, df_2013_match])\n",
    "dataframe_2013_2015.reset_index(drop=True, inplace=True)\n",
    "dataframe_2013_2015.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reassign the dataframe to dataframe_v4 for continuation of the code in next section on Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v4 = dataframe_2013_2015.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to clean our data to be suitable for analysis in this section. We will perform actions on almost all of our columns based the google sheet here: \n",
    "https://docs.google.com/spreadsheets/d/1jVtQ1TYKtLA9SFqdjPmhYl1fqRrUywjBrI5U5cKXbBo/edit#gid=51570131 . A copy of the analysis file (`Variable list.xlsx`) is available in the data/ folder.\n",
    "\n",
    "For easy readability, we will do the actions on a feature level with explanation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVDINFR4</th>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <th>ASTHMA3</th>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <th>CHCOCNCR</th>\n",
       "      <th>CHCCOPD1</th>\n",
       "      <th>ADDEPEV2</th>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>SEX</th>\n",
       "      <th>...</th>\n",
       "      <th>_EDUCAG</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>DRNKANY5</th>\n",
       "      <th>_RFBING5</th>\n",
       "      <th>_DRNKWEK</th>\n",
       "      <th>_FRTLT1</th>\n",
       "      <th>_VEGLT1</th>\n",
       "      <th>_PA150R2</th>\n",
       "      <th>_RFCHOL</th>\n",
       "      <th>WTKG3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7484.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.990000e+04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6441.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CVDINFR4  CVDSTRK3  ASTHMA3  CHCSCNCR  CHCOCNCR  CHCCOPD1  ADDEPEV2  \\\n",
       "0       2.0       2.0      1.0       2.0       2.0       1.0       1.0   \n",
       "1       2.0       2.0      2.0       2.0       2.0       2.0       2.0   \n",
       "2       7.0       1.0      2.0       2.0       1.0       2.0       2.0   \n",
       "3       2.0       2.0      2.0       2.0       1.0       2.0       1.0   \n",
       "4       2.0       2.0      2.0       2.0       2.0       2.0       2.0   \n",
       "\n",
       "   CHCKIDNY  DIABETE3  SEX  ...  _EDUCAG  _SMOKER3  DRNKANY5  _RFBING5  \\\n",
       "0       2.0       3.0  2.0  ...      2.0       3.0       2.0       1.0   \n",
       "1       2.0       3.0  2.0  ...      4.0       1.0       2.0       1.0   \n",
       "2       2.0       3.0  2.0  ...      2.0       9.0       9.0       9.0   \n",
       "3       2.0       3.0  2.0  ...      2.0       4.0       2.0       1.0   \n",
       "4       2.0       3.0  2.0  ...      3.0       4.0       2.0       1.0   \n",
       "\n",
       "       _DRNKWEK  _FRTLT1  _VEGLT1  _PA150R2  _RFCHOL    WTKG3  \n",
       "0  5.397605e-79      2.0      1.0       3.0      2.0  12701.0  \n",
       "1  5.397605e-79      2.0      2.0       1.0      1.0   7484.0  \n",
       "2  9.990000e+04      9.0      9.0       9.0      2.0   7167.0  \n",
       "3  5.397605e-79      1.0      2.0       3.0      2.0   8165.0  \n",
       "4  5.397605e-79      9.0      1.0       3.0      1.0   6441.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Column name: _RFCHOL\n",
    "# Replace missing values with 0. Standardardize response for analysis.\n",
    "\n",
    "dataframe_v4[\"_RFCHOL\"] = dataframe_v4[\"_RFCHOL\"].fillna(1)\n",
    "dataframe_v4[\"_RFCHOL\"] = dataframe_v4[\"_RFCHOL\"].map( lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "# Column name: WTKG3\n",
    "# Replace missing values with mean weight\n",
    "mean_weight = dataframe_v4[\"WTKG3\"].mean()\n",
    "dataframe_v4[\"WTKG3\"] = dataframe_v4[\"WTKG3\"].fillna(mean_weight)\n",
    "\n",
    "# Column name: HTM4\n",
    "# Replace missing values with mean height\n",
    "mean_height = dataframe_v4[\"HTM4\"].mean()\n",
    "dataframe_v4[\"HTM4\"] = dataframe_v4[\"HTM4\"].fillna(mean_height)\n",
    "\n",
    "# Column name: DIFFWALK\n",
    "# Assume no for null values, define uncertain and refusal response as no \n",
    "dataframe_v4[\"DIFFWALK\"] = dataframe_v4[\"DIFFWALK\"].fillna(2)\n",
    "dataframe_v4[\"DIFFWALK\"] = dataframe_v4[\"DIFFWALK\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: BLIND\n",
    "# Assume no for null values, define uncertain and refusal response as no \n",
    "dataframe_v4[\"BLIND\"] = dataframe_v4[\"BLIND\"].fillna(2)\n",
    "dataframe_v4[\"BLIND\"] = dataframe_v4[\"BLIND\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "\n",
    "# Column name: _MICHD \n",
    "# Assume no for null values, define uncertain and refusal response as no \n",
    "dataframe_v4[\"_MICHD\"] = dataframe_v4[\"_MICHD\"].fillna(2)\n",
    "dataframe_v4[\"_MICHD\"] = dataframe_v4[\"_MICHD\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: _DRDXAR1\n",
    "# Assume no for null values, define uncertain and refusal response as no \n",
    "dataframe_v4[\"_DRDXAR1\"] = dataframe_v4[\"_DRDXAR1\"].fillna(2)\n",
    "dataframe_v4[\"_DRDXAR1\"] = dataframe_v4[\"_DRDXAR1\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: DIABETE3\n",
    "# Assume no for null values, define uncertain and refusal response as no \n",
    "dataframe_v4[\"DIABETE3\"] = dataframe_v4[\"DIABETE3\"].fillna(3)\n",
    "dataframe_v4[\"DIABETE3\"] = dataframe_v4[\"DIABETE3\"].map( lambda x : 1 if x < 3 else 0)\n",
    "\n",
    "# Column name: CHCSCNCR\n",
    "# Assume no for null values, define uncertain and refusal response as no \n",
    "dataframe_v4[\"CHCSCNCR\"] = dataframe_v4[\"CHCSCNCR\"].fillna(2)\n",
    "dataframe_v4[\"CHCSCNCR\"] = dataframe_v4[\"CHCSCNCR\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: _DRNKWEK \n",
    "# Assume column mean for 99900 (no data) \n",
    "mean_drinks = dataframe_v4[\"_DRNKWEK\"].mean()\n",
    "dataframe_v4[\"_DRNKWEK\"] = dataframe_v4[\"_DRNKWEK\"].replace(99900, mean_drinks)\n",
    "\n",
    "# Column name: SEX\n",
    "# 1 as male. 0 as female.\n",
    "dataframe_v4[\"SEX\"] = dataframe_v4[\"SEX\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: MARITAL\n",
    "# Define married as married. Others classify as not married (0).\n",
    "dataframe_v4[\"MARITAL\"] = dataframe_v4[\"MARITAL\"].map( lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: EMPLOY1\n",
    "# Simplified to only employed (1) and others\n",
    "dataframe_v4[\"EMPLOY1\"] = dataframe_v4[\"EMPLOY1\"].map( lambda x : 1 if x in [1,2] else 0)\n",
    "\n",
    "# Column name: _AGEG5YR\n",
    "# Impute mean age category to people who were unwilling to disclose age\n",
    "mean_age_group = int(dataframe_v4[\"_AGEG5YR\"].mean())\n",
    "dataframe_v4[\"_AGEG5YR\"] = dataframe_v4[\"_AGEG5YR\"].map( lambda x : mean_age_group if x == 14 else x)\n",
    "\n",
    "# Column name: _EDUCAG\n",
    "# Simplify education to three categories\n",
    "# 0 - Did not graduate high school\n",
    "# 1 - high school graduate\n",
    "# 2 - College or Tech school grad\n",
    "dataframe_v4[\"_EDUCAG\"] = dataframe_v4[\"_EDUCAG\"].map( lambda x : 0 if x in [1,9] else (1 if x in [2,3] else 2))  \n",
    "\n",
    "# Column name: _PA150R2\n",
    "# Simplify category to three categories. Impute 9 to 2.\n",
    "# 0 - 0 minutes of vigorous exercise\n",
    "# 1 - 1 to 149 minutes of vigorous exercise\n",
    "# 2 - more than 150 minutes of vigorous exercise\n",
    "dataframe_v4[\"_PA150R2\"] = dataframe_v4[\"_PA150R2\"].map(lambda x : 0 if x == 3 else (2 if x == 1 else 1))\n",
    "\n",
    "# Column name: _FRTLT1\n",
    "# Simplify category to two categories. \n",
    "# 0 - consumed fruits less than one time per day\n",
    "# 1 - consume fruits more than one time per day\n",
    "dataframe_v4[\"_FRTLT1\"] = dataframe_v4[\"_FRTLT1\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: _VEGLT1\n",
    "# Simplify category to two categories.\n",
    "# 0 - consumed veg less than one time per day\n",
    "# 1 - consume veg more than one time per day\n",
    "dataframe_v4[\"_VEGLT1\"] = dataframe_v4[\"_VEGLT1\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: CVDINFR4\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"CVDINFR4\"] = dataframe_v4[\"CVDINFR4\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: CVDSTRK3\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"CVDSTRK3\"] = dataframe_v4[\"CVDSTRK3\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: ASTHMA3\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"ASTHMA3\"] = dataframe_v4[\"ASTHMA3\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: CHCOCNCR\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"CHCOCNCR\"] = dataframe_v4[\"CHCOCNCR\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: CHCCOPD1\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"CHCCOPD1\"] = dataframe_v4[\"CHCCOPD1\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: ADDEPEV2\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"ADDEPEV2\"] = dataframe_v4[\"ADDEPEV2\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: CHCKIDNY\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"CHCKIDNY\"] = dataframe_v4[\"CHCKIDNY\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: _RFHYPE5\n",
    "# Simplify category to two categories.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"_RFHYPE5\"] = dataframe_v4[\"_RFHYPE5\"].map(lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "# Column name: _SMOKER3\n",
    "# Map those who refuse to answer and missing data to non-smoker. \n",
    "# Revise response variable to oridinal for easy analysis. \n",
    "# 0 - never smoke\n",
    "# 1 - former smoker\n",
    "# 2 - current smoker (smoke some days)\n",
    "# 3 - current smoker (smoke every day)\n",
    "dataframe_v4[\"_SMOKER3\"] = dataframe_v4[\"_SMOKER3\"].map(lambda x : 3 if x == 1 else ( 2 if x == 2 else (1 if x == 3 else 0)))\n",
    "\n",
    "# Column name: DRNKANY5\n",
    "# Map those who refuse to answer as Yes and missing data as No.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"DRNKANY5\"] = dataframe_v4[\"DRNKANY5\"].map(lambda x : 1 if x == 7 else (2 if x == 9 else x))\n",
    "dataframe_v4[\"DRNKANY5\"] = dataframe_v4[\"DRNKANY5\"].map(lambda x : 1 if x == 1 else 0)\n",
    "\n",
    "# Column name: _RFBING5\n",
    "# Map those who refuse to answer and missing data as No.\n",
    "# 0 - No and others\n",
    "# 1 - Yes\n",
    "dataframe_v4[\"_RFBING5\"] = dataframe_v4[\"_RFBING5\"].map(lambda x : 1 if x == 2 else 0)\n",
    "\n",
    "# Column name: ALCDAY5\n",
    "# we redefine feature to days per month\n",
    "dataframe_v4[\"ALCDAY5\"] = dataframe_v4[\"ALCDAY5\"].map(lambda x : 0 if x in [777,888,999] else x)\n",
    "dataframe_v4[\"ALCDAY5\"] = dataframe_v4[\"ALCDAY5\"].map(lambda x : (x*4)-400 if x in range(100,199) else x)\n",
    "dataframe_v4[\"ALCDAY5\"] = dataframe_v4[\"ALCDAY5\"].map(lambda x : x-200 if x in range (200,299) else x)\n",
    "mean_days_drink_month = dataframe_v4[\"ALCDAY5\"].mean()\n",
    "dataframe_v4[\"ALCDAY5\"] = dataframe_v4[\"ALCDAY5\"].fillna(mean_days_drink_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field level transformation is done. Proceed to clean up NA data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVDINFR4     0\n",
       "CVDSTRK3     0\n",
       "ASTHMA3      0\n",
       "CHCSCNCR     0\n",
       "CHCOCNCR     0\n",
       "CHCCOPD1     0\n",
       "ADDEPEV2     0\n",
       "CHCKIDNY     0\n",
       "DIABETE3     0\n",
       "SEX          0\n",
       "MARITAL      0\n",
       "EMPLOY1      0\n",
       "BLIND        0\n",
       "DIFFWALK     0\n",
       "ALCDAY5      0\n",
       "_RFHYPE5     0\n",
       "_MICHD       0\n",
       "_DRDXAR1     0\n",
       "_RACE       25\n",
       "_AGEG5YR     0\n",
       "HTM4         0\n",
       "_EDUCAG      0\n",
       "_SMOKER3     0\n",
       "DRNKANY5     0\n",
       "_RFBING5     0\n",
       "_DRNKWEK     0\n",
       "_FRTLT1      0\n",
       "_VEGLT1      0\n",
       "_PA150R2     0\n",
       "_RFCHOL      0\n",
       "WTKG3        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v4.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_RACE` with NA cannot be assumed a value, therefore proceed to drop them (i.e. 25 records is 0.0025% of total data rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v4.dropna(subset=['_RACE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVDINFR4    0\n",
       "CVDSTRK3    0\n",
       "ASTHMA3     0\n",
       "CHCSCNCR    0\n",
       "CHCOCNCR    0\n",
       "CHCCOPD1    0\n",
       "ADDEPEV2    0\n",
       "CHCKIDNY    0\n",
       "DIABETE3    0\n",
       "SEX         0\n",
       "MARITAL     0\n",
       "EMPLOY1     0\n",
       "BLIND       0\n",
       "DIFFWALK    0\n",
       "ALCDAY5     0\n",
       "_RFHYPE5    0\n",
       "_MICHD      0\n",
       "_DRDXAR1    0\n",
       "_RACE       0\n",
       "_AGEG5YR    0\n",
       "HTM4        0\n",
       "_EDUCAG     0\n",
       "_SMOKER3    0\n",
       "DRNKANY5    0\n",
       "_RFBING5    0\n",
       "_DRNKWEK    0\n",
       "_FRTLT1     0\n",
       "_VEGLT1     0\n",
       "_PA150R2    0\n",
       "_RFCHOL     0\n",
       "WTKG3       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v4.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more data with NA.  Proceed to check and transform data type, if required. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CVDINFR4</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.058666</td>\n",
       "      <td>0.234998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVDSTRK3</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.041424</td>\n",
       "      <td>0.199269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASTHMA3</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.135638</td>\n",
       "      <td>0.342404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHCSCNCR</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.093551</td>\n",
       "      <td>0.291203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHCOCNCR</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.097059</td>\n",
       "      <td>0.296038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHCCOPD1</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>0.273796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADDEPEV2</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.192410</td>\n",
       "      <td>0.394194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHCKIDNY</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>0.180774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIABETE3</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.136960</td>\n",
       "      <td>0.343806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.415984</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MARITAL</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.521315</td>\n",
       "      <td>0.499546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMPLOY1</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.490555</td>\n",
       "      <td>0.499911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLIND</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.050578</td>\n",
       "      <td>0.219135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIFFWALK</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.172671</td>\n",
       "      <td>0.377963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALCDAY5</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>4.574287</td>\n",
       "      <td>7.854243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.574311</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_RFHYPE5</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.404043</td>\n",
       "      <td>0.490706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_MICHD</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.088990</td>\n",
       "      <td>0.284730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_DRDXAR1</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.335643</td>\n",
       "      <td>0.472215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_RACE</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>2.003162</td>\n",
       "      <td>2.254127</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_AGEG5YR</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>7.655081</td>\n",
       "      <td>3.431637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HTM4</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>169.369201</td>\n",
       "      <td>10.408297</td>\n",
       "      <td>91.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.693693e+02</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_EDUCAG</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>1.269326</td>\n",
       "      <td>0.607647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_SMOKER3</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.681103</td>\n",
       "      <td>0.967774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRNKANY5</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.485573</td>\n",
       "      <td>0.499792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_RFBING5</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.117268</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_DRNKWEK</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>330.503473</td>\n",
       "      <td>891.384366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>53200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_FRTLT1</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.572539</td>\n",
       "      <td>0.494710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_VEGLT1</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.706618</td>\n",
       "      <td>0.455312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_PA150R2</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>1.202589</td>\n",
       "      <td>0.826279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_RFCHOL</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>0.368106</td>\n",
       "      <td>0.482291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTKG3</th>\n",
       "      <td>933204.0</td>\n",
       "      <td>8048.080759</td>\n",
       "      <td>2028.685366</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>6668.0</td>\n",
       "      <td>7.938000e+03</td>\n",
       "      <td>9072.000000</td>\n",
       "      <td>29030.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count         mean          std     min     25%           50%  \\\n",
       "CVDINFR4  933204.0     0.058666     0.234998     0.0     0.0  0.000000e+00   \n",
       "CVDSTRK3  933204.0     0.041424     0.199269     0.0     0.0  0.000000e+00   \n",
       "ASTHMA3   933204.0     0.135638     0.342404     0.0     0.0  0.000000e+00   \n",
       "CHCSCNCR  933204.0     0.093551     0.291203     0.0     0.0  0.000000e+00   \n",
       "CHCOCNCR  933204.0     0.097059     0.296038     0.0     0.0  0.000000e+00   \n",
       "CHCCOPD1  933204.0     0.081627     0.273796     0.0     0.0  0.000000e+00   \n",
       "ADDEPEV2  933204.0     0.192410     0.394194     0.0     0.0  0.000000e+00   \n",
       "CHCKIDNY  933204.0     0.033823     0.180774     0.0     0.0  0.000000e+00   \n",
       "DIABETE3  933204.0     0.136960     0.343806     0.0     0.0  0.000000e+00   \n",
       "SEX       933204.0     0.415984     0.492891     0.0     0.0  0.000000e+00   \n",
       "MARITAL   933204.0     0.521315     0.499546     0.0     0.0  1.000000e+00   \n",
       "EMPLOY1   933204.0     0.490555     0.499911     0.0     0.0  0.000000e+00   \n",
       "BLIND     933204.0     0.050578     0.219135     0.0     0.0  0.000000e+00   \n",
       "DIFFWALK  933204.0     0.172671     0.377963     0.0     0.0  0.000000e+00   \n",
       "ALCDAY5   933204.0     4.574287     7.854243     0.0     0.0  1.000000e+00   \n",
       "_RFHYPE5  933204.0     0.404043     0.490706     0.0     0.0  0.000000e+00   \n",
       "_MICHD    933204.0     0.088990     0.284730     0.0     0.0  0.000000e+00   \n",
       "_DRDXAR1  933204.0     0.335643     0.472215     0.0     0.0  0.000000e+00   \n",
       "_RACE     933204.0     2.003162     2.254127     1.0     1.0  1.000000e+00   \n",
       "_AGEG5YR  933204.0     7.655081     3.431637     1.0     5.0  8.000000e+00   \n",
       "HTM4      933204.0   169.369201    10.408297    91.0   163.0  1.693693e+02   \n",
       "_EDUCAG   933204.0     1.269326     0.607647     0.0     1.0  1.000000e+00   \n",
       "_SMOKER3  933204.0     0.681103     0.967774     0.0     0.0  0.000000e+00   \n",
       "DRNKANY5  933204.0     0.485573     0.499792     0.0     0.0  0.000000e+00   \n",
       "_RFBING5  933204.0     0.117268     0.321740     0.0     0.0  0.000000e+00   \n",
       "_DRNKWEK  933204.0   330.503473   891.384366     0.0     0.0  5.397605e-79   \n",
       "_FRTLT1   933204.0     0.572539     0.494710     0.0     0.0  1.000000e+00   \n",
       "_VEGLT1   933204.0     0.706618     0.455312     0.0     0.0  1.000000e+00   \n",
       "_PA150R2  933204.0     1.202589     0.826279     0.0     0.0  1.000000e+00   \n",
       "_RFCHOL   933204.0     0.368106     0.482291     0.0     0.0  0.000000e+00   \n",
       "WTKG3     933204.0  8048.080759  2028.685366  2268.0  6668.0  7.938000e+03   \n",
       "\n",
       "                  75%      max  \n",
       "CVDINFR4     0.000000      1.0  \n",
       "CVDSTRK3     0.000000      1.0  \n",
       "ASTHMA3      0.000000      1.0  \n",
       "CHCSCNCR     0.000000      1.0  \n",
       "CHCOCNCR     0.000000      1.0  \n",
       "CHCCOPD1     0.000000      1.0  \n",
       "ADDEPEV2     0.000000      1.0  \n",
       "CHCKIDNY     0.000000      1.0  \n",
       "DIABETE3     0.000000      1.0  \n",
       "SEX          1.000000      1.0  \n",
       "MARITAL      1.000000      1.0  \n",
       "EMPLOY1      1.000000      1.0  \n",
       "BLIND        0.000000      1.0  \n",
       "DIFFWALK     0.000000      1.0  \n",
       "ALCDAY5      4.574311     30.0  \n",
       "_RFHYPE5     1.000000      1.0  \n",
       "_MICHD       0.000000      1.0  \n",
       "_DRDXAR1     1.000000      1.0  \n",
       "_RACE        1.000000      9.0  \n",
       "_AGEG5YR    10.000000     13.0  \n",
       "HTM4       178.000000    241.0  \n",
       "_EDUCAG      2.000000      2.0  \n",
       "_SMOKER3     1.000000      3.0  \n",
       "DRNKANY5     1.000000      1.0  \n",
       "_RFBING5     0.000000      1.0  \n",
       "_DRNKWEK   238.000000  53200.0  \n",
       "_FRTLT1      1.000000      1.0  \n",
       "_VEGLT1      1.000000      1.0  \n",
       "_PA150R2     2.000000      2.0  \n",
       "_RFCHOL      1.000000      1.0  \n",
       "WTKG3     9072.000000  29030.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_v4.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 933204 entries, 0 to 933228\n",
      "Data columns (total 31 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   CVDINFR4  933204 non-null  int64  \n",
      " 1   CVDSTRK3  933204 non-null  int64  \n",
      " 2   ASTHMA3   933204 non-null  int64  \n",
      " 3   CHCSCNCR  933204 non-null  int64  \n",
      " 4   CHCOCNCR  933204 non-null  int64  \n",
      " 5   CHCCOPD1  933204 non-null  int64  \n",
      " 6   ADDEPEV2  933204 non-null  int64  \n",
      " 7   CHCKIDNY  933204 non-null  int64  \n",
      " 8   DIABETE3  933204 non-null  int64  \n",
      " 9   SEX       933204 non-null  int64  \n",
      " 10  MARITAL   933204 non-null  int64  \n",
      " 11  EMPLOY1   933204 non-null  int64  \n",
      " 12  BLIND     933204 non-null  int64  \n",
      " 13  DIFFWALK  933204 non-null  int64  \n",
      " 14  ALCDAY5   933204 non-null  float64\n",
      " 15  _RFHYPE5  933204 non-null  int64  \n",
      " 16  _MICHD    933204 non-null  int64  \n",
      " 17  _DRDXAR1  933204 non-null  int64  \n",
      " 18  _RACE     933204 non-null  float64\n",
      " 19  _AGEG5YR  933204 non-null  float64\n",
      " 20  HTM4      933204 non-null  float64\n",
      " 21  _EDUCAG   933204 non-null  int64  \n",
      " 22  _SMOKER3  933204 non-null  int64  \n",
      " 23  DRNKANY5  933204 non-null  int64  \n",
      " 24  _RFBING5  933204 non-null  int64  \n",
      " 25  _DRNKWEK  933204 non-null  float64\n",
      " 26  _FRTLT1   933204 non-null  int64  \n",
      " 27  _VEGLT1   933204 non-null  int64  \n",
      " 28  _PA150R2  933204 non-null  int64  \n",
      " 29  _RFCHOL   933204 non-null  int64  \n",
      " 30  WTKG3     933204 non-null  float64\n",
      "dtypes: float64(6), int64(25)\n",
      "memory usage: 227.8 MB\n"
     ]
    }
   ],
   "source": [
    "dataframe_v4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are some columns that we can define them as integers instead of float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v4[\"ALCDAY5\"] = dataframe_v4[\"ALCDAY5\"].astype(int)\n",
    "dataframe_v4[\"_RACE\"] = dataframe_v4[\"_RACE\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 933204 entries, 0 to 933228\n",
      "Data columns (total 31 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   CVDINFR4  933204 non-null  int64  \n",
      " 1   CVDSTRK3  933204 non-null  int64  \n",
      " 2   ASTHMA3   933204 non-null  int64  \n",
      " 3   CHCSCNCR  933204 non-null  int64  \n",
      " 4   CHCOCNCR  933204 non-null  int64  \n",
      " 5   CHCCOPD1  933204 non-null  int64  \n",
      " 6   ADDEPEV2  933204 non-null  int64  \n",
      " 7   CHCKIDNY  933204 non-null  int64  \n",
      " 8   DIABETE3  933204 non-null  int64  \n",
      " 9   SEX       933204 non-null  int64  \n",
      " 10  MARITAL   933204 non-null  int64  \n",
      " 11  EMPLOY1   933204 non-null  int64  \n",
      " 12  BLIND     933204 non-null  int64  \n",
      " 13  DIFFWALK  933204 non-null  int64  \n",
      " 14  ALCDAY5   933204 non-null  int32  \n",
      " 15  _RFHYPE5  933204 non-null  int64  \n",
      " 16  _MICHD    933204 non-null  int64  \n",
      " 17  _DRDXAR1  933204 non-null  int64  \n",
      " 18  _RACE     933204 non-null  int32  \n",
      " 19  _AGEG5YR  933204 non-null  float64\n",
      " 20  HTM4      933204 non-null  float64\n",
      " 21  _EDUCAG   933204 non-null  int64  \n",
      " 22  _SMOKER3  933204 non-null  int64  \n",
      " 23  DRNKANY5  933204 non-null  int64  \n",
      " 24  _RFBING5  933204 non-null  int64  \n",
      " 25  _DRNKWEK  933204 non-null  float64\n",
      " 26  _FRTLT1   933204 non-null  int64  \n",
      " 27  _VEGLT1   933204 non-null  int64  \n",
      " 28  _PA150R2  933204 non-null  int64  \n",
      " 29  _RFCHOL   933204 non-null  int64  \n",
      " 30  WTKG3     933204 non-null  float64\n",
      "dtypes: float64(4), int32(2), int64(25)\n",
      "memory usage: 220.7 MB\n"
     ]
    }
   ],
   "source": [
    "dataframe_v4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now rename our columns to readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\n",
    "    'CHCCOPD1': 'cpd_bronchitis',\n",
    "    'ADDEPEV2': 'depression',\n",
    "    '_DRDXAR1': 'arthritis',\n",
    "    'CVDINFR4': 'heart_attack',\n",
    "    'CVDSTRK3': 'stroke',\n",
    "    'ASTHMA3': 'asthma',\n",
    "    'DIABETE3': 'diabetes',\n",
    "    'CHCKIDNY': 'kidney_disease',\n",
    "    '_MICHD': 'heart_disease',\n",
    "    'CHCSCNCR': 'skin_cancer',\n",
    "    'CHCOCNCR': 'other_cancer',\n",
    "    '_RFCHOL': 'high_cholesterol',\n",
    "    '_RFHYPE5': 'high_bp',\n",
    "    '_PA150R2': 'exercise_cat',\n",
    "    'DRNKANY5': 'one_alc_per_day',\n",
    "    'BLIND': 'blind',\n",
    "    'MARITAL': 'martial',\n",
    "    '_RFBING5': 'binge_drink',\n",
    "    '_DRNKWEK': 'ave_drink_week',\n",
    "    '_FRTLT1': 'fruit',\n",
    "    '_VEGLT1': 'vegetable',\n",
    "    'DIFFWALK': 'diff_walking',\n",
    "    'ALCDAY5': 'occasion_drink_30days',\n",
    "    'EMPLOY1': 'employment_status',\n",
    "    '_SMOKER3': 'smoker_status',\n",
    "    '_AGEG5YR': 'age',\n",
    "    'SEX': 'sex',\n",
    "    '_EDUCAG': 'education',\n",
    "    '_RACE': 'race',\n",
    "    'HTM4': 'height',\n",
    "    'WTKG3': 'weight'\n",
    "}\n",
    "\n",
    "# Renaming the columns\n",
    "dataframe_v4.rename(columns=new_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Export Dataset for EDA\n",
    "Export the cleaned dataframe into CSV - for Feature Engineering and EDA \n",
    "\n",
    "- `02_cleaned_data_forEDA.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_v4.to_csv(f\"../data/02_cleaned_data_forEDA.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
